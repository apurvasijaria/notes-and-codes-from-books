{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation \n",
    "\n",
    "\n",
    "You can flatten out the features and try some classical methods like SVM, RF for  doing classification, which is perfectly fine, but it won't get you anywhere near state  of the art. Also, the images are of size 1024x1024. It’s going to take a long time to  train a model on this dataset. For what it’s worth, let’s try building a simple random  forest model on this data. Since the images are grayscale, we do not need to do any  kind of conversion. We will resize the images to 256x256 to make them smaller and  use AUC as a metric as discussed before. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn import ensemble\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_dataset (training_df, image_dir):\n",
    "    images = []\n",
    "    targets = []\n",
    "    for index,rows in tqdm(training_df.iterrows(),total = len(training_df),desc = \"processing_images\"):\n",
    "        image_id = row[\"ImageId\"]\n",
    "        image_path = os.path.join(image_dir,image_id)\n",
    "        image = Image.open(image_path+\".png\")\n",
    "        image = image.resize((256,256),resample = Image.BILINEAR)\n",
    "        image = np.array(image)\n",
    "        image = image.ravel()\n",
    "        images.append(image)\n",
    "        targets.append(int(row[\"target\"]))\n",
    "    images = np.array(images)\n",
    "    print(images.shape)\n",
    "    return images,targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AlexNet - base of all Deep Convolution Neural network\n",
    "- Filters - 2 dimenstion matrices initated with move accross the imge\n",
    "- Strides - how many pixels the center of the filter moves in one time\n",
    "- padding - adding some 0 level pixels around the image to capture the corner and edged in the filters\n",
    "- dilations - gap in the pixels of fitlers, dilation =1 side by side, dilation =2 alternate \n",
    "- pooling - the resulting of filter, \n",
    "    - max pooling - max of the pixel values in the filter\n",
    "    - average pooling - average of the pixel values in the filter\n",
    "    \n",
    "    \n",
    " -----\n",
    " \n",
    " PyTorch. PyTorch provides an intuitive and easy way to implement deep  neural networks, and you don’t need to care about back-propagation. We define the  network in a python class and a forward function that tells PyTorch how the layers  are connected to each other. In PyTorch, the image notation is BS, C, H, W, where,  BS is the batch size, C channels, H is height and W is the width. Let’s see how  AlexNet is implemented in PyTorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-84c6fab5f56b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-cbc22b1015ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mAlexNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                 \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAlexNet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[1;33m(\u001b[0m  \u001b[0min_channels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mout_channels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m96\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m  \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaxPool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "class AlexNet(nn.Module):  \n",
    "\tdef __init__(self):  \n",
    "\t\tsuper(AlexNet, self).__init__()  \n",
    "\t\tself.conv1 = nn.Conv2d(  in_channels=3,  out_channels=96,  kernel_size=11,  stride=4,  padding=0  )  \n",
    "\t\tself.pool1 = nn.MaxPool2d(kernel_size=3, stride=2)  \n",
    "\t\tself.conv2 = nn.Conv2d(  in_channels=96,  out_channels=256,  kernel_size=5,  stride=1,  padding=2  )  \n",
    "\t\tself.pool2 = nn.MaxPool2d(kernel_size=3, stride=2)  \n",
    "\t\tself.conv3 = nn.Conv2d(  in_channels=256,  out_channels=384,  kernel_size=3,  stride=1,  padding=1  )  \n",
    "\t\tself.conv4 = nn.Conv2d(in_channels=384,out_channels=384,  kernel_size=3, stride=1,padding=1) \n",
    "\t\tself.conv5 = nn.Conv2d(in_channels=384, out_channels=256,  kernel_size=3,  stride=1,  padding=1  )  \n",
    "\t\tself.pool3 = nn.MaxPool2d(kernel_size=3, stride=2)  #dense part  \n",
    "\t\tself.fc1 = nn.Linear(  in_features=9216,  out_features=4096  )  \n",
    "\t\tself.dropout1 = nn.Dropout(0.5)  \n",
    "\t\tself.fc2 = nn.Linear(  in_features=4096,  out_features=4096  )  \n",
    "\t\tself.dropout2 = nn.Dropout(0.5)  \n",
    "\t\tself.fc3 = nn.Linear(  in_features=4096,  out_features=1000  ) \n",
    "\n",
    "\tdef forward(self, image):  \n",
    "\t\tbs, c, h, w = image.size()  \n",
    "\t\tx = F.relu(self.conv1(image)) #size: (bs, 96, 55, 55)  \n",
    "\t\tx = self.pool1(x) #size: (bs, 96, 27, 27)  \n",
    "\t\tx = F.relu(self.conv2(x)) #size: (bs, 256, 27, 27)  \n",
    "\t\tx = self.pool2(x) #size: (bs, 256, 13, 13)  \n",
    "\t\tx = F.relu(self.conv3(x)) #size: (bs, 384, 13, 13)  \n",
    "\t\tx = F.relu(self.conv4(x)) #size: (bs, 384, 13, 13)  \n",
    "\t\tx = F.relu(self.conv5(x)) #size: (bs, 256, 13, 13)  \n",
    "\t\tx = self.pool3(x)\n",
    "\t\tsize: (bs, 9216)  \n",
    "\t\tx = F.relu(self.fc1(x)) \n",
    "\t\tsize: (bs, 4096)  \n",
    "\t\tx = self.dropout1(x) \n",
    "\t\tsize: (bs, 4096)  \n",
    "\t\tx = F.relu(self.fc2(x)) \n",
    "\t\tsize: (bs, 4096)  \n",
    "\t\tx = self.dropout2(x) \n",
    "\t\tsize: (bs, 4096)  \n",
    "\t\tx = F.relu(self.fc3(x)) \n",
    "\t\tsize: (bs, 1000)  \n",
    "\t\tx = torch.softmax(x, axis=1) \n",
    "\t\tsize: (bs, 1000) \n",
    "\t\treturn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
