{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Neural Networks are much more complex than the shallow NN trained in last chapter. Issues in trianing DNN:\n",
    "\n",
    "- vanishing graidents or exploding gradients\n",
    "- not enough training data\n",
    "- slow training\n",
    "- overfitting the trianing set\n",
    "\n",
    "\n",
    "### Vanishing and Exploding Gradients\n",
    "\n",
    "In backpropogation, the algo works by going from the output layer to the input layer and propogating the error gradient along the way. gradients often get small and smaller as the algorithm progressed down to the lower layers. resulting in no change in the lower layer leaved and training never converging to a good solution. this is called vanishing gradietns. \n",
    "\n",
    "In some cases, opposite happends, the gradients grow bigger and bigger until the layers get insanely large weight updates andthe algo diverges, this is called exploding gradients, which resurfaces in recurrent NN. \n",
    "\n",
    "MMore generaly, DNN suffer from unstable gradients, different layers may learn at widely different speeds.\n",
    "\n",
    "This was concluded in a 2010 study, that sigmoid function saturates at 0 or 1, hence the sgd has no gradient to propogate back from. \n",
    "\n",
    "__Glorot and He Initialization__\n",
    "\n",
    "for signifficantly allecviate the unstable gradient problem. we need to signal the flow properly in both directions: in the forward direction when making the predictions and in reverse direction when backpropogating gradients. we don't want the signal to die out or explode and saturate. for the signal to flow properly, we need the vairance of the outputs of each layer to be equal to the variance of its inputs and we need the graideitns tp have equal variance before and after flowing through a layer in reverse direction. it's not possible unless the layer has an equal number of input and neurons (fan in and fan out of the layer), but glorot and bengio proposed a compromize that is proven to work in ractive. the connection weights of each layer must be initialized randomly as ${fan}_{avg} = ({fan}_{in} + {fan}_{out})/2$.  this is called _xavier initialization or glorot initializtion_ \n",
    "\n",
    "\n",
    "| Initialization | Activation functions | σ² (Normal)|\n",
    "| :-: | :-: | :-: |\n",
    "| Glorot |  None, tanh, logistic, softmax | $ \\frac 1 {{fan}_{avg}}$|\n",
    "| He | ReLU and variants | $ \\frac 2 {{fan}_{in}}$ |\n",
    "| LeCun | SELU | $ \\frac 1 {{fan}_{in}}$|\n",
    "\n",
    "\n",
    "By default, Keras uses Glorot initialization with a uniform distribution. When creating a layer, you can change this to He initialization by setting `kernel_initializer=\"he_uniform\"` or `kernel_initializer=\"he_normal\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fmnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating validation dataset and scaling the dataset\n",
    "\n",
    "X_val, X_train = X_train[:5000],X_train[5000:]\n",
    "y_val, y_train = y_train[:5000],y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test = X_train/255.0, X_val/255.0,X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##labels from https://keras.io/api/datasets/fashion_mnist/#loaddata-function\n",
    "labels = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "keras.layers.Flatten(input_shape=[28, 28]),\n",
    "keras.layers.Dense(100, activation=\"relu\",kernel_initializer = \"he_normal\"),\n",
    "keras.layers.Dense(100, activation=\"relu\",kernel_initializer = \"he_normal\"),\n",
    "keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 5s 2ms/step - loss: 0.7203 - accuracy: 0.7575 - val_loss: 0.5084 - val_accuracy: 0.8266\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4945 - accuracy: 0.8271 - val_loss: 0.4685 - val_accuracy: 0.8432\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4498 - accuracy: 0.8420 - val_loss: 0.4171 - val_accuracy: 0.8606\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4232 - accuracy: 0.8505 - val_loss: 0.4685 - val_accuracy: 0.8312\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4024 - accuracy: 0.8602 - val_loss: 0.3893 - val_accuracy: 0.8634\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3889 - accuracy: 0.8628 - val_loss: 0.3890 - val_accuracy: 0.8642\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3749 - accuracy: 0.8686 - val_loss: 0.3595 - val_accuracy: 0.8746\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3633 - accuracy: 0.8714 - val_loss: 0.3646 - val_accuracy: 0.8700\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3530 - accuracy: 0.8756 - val_loss: 0.3781 - val_accuracy: 0.8696\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3444 - accuracy: 0.8770 - val_loss: 0.3663 - val_accuracy: 0.8714\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3369 - accuracy: 0.8796 - val_loss: 0.3644 - val_accuracy: 0.8726\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3300 - accuracy: 0.8811 - val_loss: 0.3346 - val_accuracy: 0.8806\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3221 - accuracy: 0.8833 - val_loss: 0.3298 - val_accuracy: 0.8792\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3159 - accuracy: 0.8861 - val_loss: 0.3386 - val_accuracy: 0.8778\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3108 - accuracy: 0.8882 - val_loss: 0.3454 - val_accuracy: 0.8740\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3048 - accuracy: 0.8904 - val_loss: 0.3301 - val_accuracy: 0.8774\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3001 - accuracy: 0.8918 - val_loss: 0.3297 - val_accuracy: 0.8830\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2954 - accuracy: 0.8935 - val_loss: 0.3212 - val_accuracy: 0.8836\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2910 - accuracy: 0.8944 - val_loss: 0.3641 - val_accuracy: 0.8708\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2865 - accuracy: 0.8952 - val_loss: 0.3202 - val_accuracy: 0.8872\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2813 - accuracy: 0.8982 - val_loss: 0.3303 - val_accuracy: 0.8794\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2778 - accuracy: 0.8999 - val_loss: 0.3174 - val_accuracy: 0.8854\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2736 - accuracy: 0.9015 - val_loss: 0.3232 - val_accuracy: 0.8824\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2692 - accuracy: 0.9026 - val_loss: 0.3059 - val_accuracy: 0.8884\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2661 - accuracy: 0.9034 - val_loss: 0.3128 - val_accuracy: 0.8866\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2629 - accuracy: 0.9045 - val_loss: 0.3180 - val_accuracy: 0.8858\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2590 - accuracy: 0.9052 - val_loss: 0.3167 - val_accuracy: 0.8884\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2559 - accuracy: 0.9070 - val_loss: 0.3217 - val_accuracy: 0.8794\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2523 - accuracy: 0.9081 - val_loss: 0.3143 - val_accuracy: 0.8880\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2498 - accuracy: 0.9098 - val_loss: 0.3070 - val_accuracy: 0.8908\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/ch_11/keras_gerlot_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3410 - accuracy: 0.8769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3410279452800751, 0.8769000172615051]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want He initialization with a uniform distribution but based on ${fan}_{avg}$ rather than ${fan}_{in}$ , you can use the VarianceScaling initializer like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_avg_init = keras.initializers.VarianceScaling(scale=2, mode='fan_avg', distribution = \"uniform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "keras.layers.Flatten(input_shape=[28, 28]),\n",
    "keras.layers.Dense(100, activation=\"sigmoid\",kernel_initializer = he_avg_init),\n",
    "keras.layers.Dense(100, activation=\"sigmoid\",kernel_initializer = he_avg_init),\n",
    "keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.9201 - accuracy: 0.4789 - val_loss: 1.4934 - val_accuracy: 0.5956\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 1.2520 - accuracy: 0.6496 - val_loss: 1.0548 - val_accuracy: 0.7136\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.9580 - accuracy: 0.7067 - val_loss: 0.8606 - val_accuracy: 0.7288\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.8094 - accuracy: 0.7319 - val_loss: 0.7483 - val_accuracy: 0.7530\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.7225 - accuracy: 0.7475 - val_loss: 0.6813 - val_accuracy: 0.7596\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.6677 - accuracy: 0.7601 - val_loss: 0.6363 - val_accuracy: 0.7738\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.6295 - accuracy: 0.7722 - val_loss: 0.6022 - val_accuracy: 0.7854\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5999 - accuracy: 0.7835 - val_loss: 0.5744 - val_accuracy: 0.7980\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5756 - accuracy: 0.7939 - val_loss: 0.5522 - val_accuracy: 0.8052\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5549 - accuracy: 0.8031 - val_loss: 0.5312 - val_accuracy: 0.8164\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5373 - accuracy: 0.8097 - val_loss: 0.5147 - val_accuracy: 0.8220\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5221 - accuracy: 0.8154 - val_loss: 0.5038 - val_accuracy: 0.8236\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5092 - accuracy: 0.8199 - val_loss: 0.4901 - val_accuracy: 0.8344\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4978 - accuracy: 0.8247 - val_loss: 0.4815 - val_accuracy: 0.8358\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4878 - accuracy: 0.8283 - val_loss: 0.4723 - val_accuracy: 0.8384\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4793 - accuracy: 0.8309 - val_loss: 0.4632 - val_accuracy: 0.8386\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4714 - accuracy: 0.8328 - val_loss: 0.4558 - val_accuracy: 0.8400\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4645 - accuracy: 0.8355 - val_loss: 0.4491 - val_accuracy: 0.8428\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4581 - accuracy: 0.8373 - val_loss: 0.4446 - val_accuracy: 0.8450\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4524 - accuracy: 0.8398 - val_loss: 0.4421 - val_accuracy: 0.8472\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4471 - accuracy: 0.8422 - val_loss: 0.4356 - val_accuracy: 0.8498\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4422 - accuracy: 0.8435 - val_loss: 0.4323 - val_accuracy: 0.8528\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4375 - accuracy: 0.8450 - val_loss: 0.4276 - val_accuracy: 0.8512\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4331 - accuracy: 0.8467 - val_loss: 0.4241 - val_accuracy: 0.8530\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4290 - accuracy: 0.8479 - val_loss: 0.4201 - val_accuracy: 0.8546\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4252 - accuracy: 0.8488 - val_loss: 0.4179 - val_accuracy: 0.8554\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4214 - accuracy: 0.8503 - val_loss: 0.4173 - val_accuracy: 0.8570\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4180 - accuracy: 0.8517 - val_loss: 0.4147 - val_accuracy: 0.8562\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4146 - accuracy: 0.8528 - val_loss: 0.4099 - val_accuracy: 0.8586\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4112 - accuracy: 0.8544 - val_loss: 0.4067 - val_accuracy: 0.8600\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/ch_11/keras_gerlot_favg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.8375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.44819024205207825, 0.8374999761581421]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonsaturating Activation Functions\n",
    "\n",
    "In 2010 paper by Glorot and Bengio, insights was that the problem with the unstable gradient was the poor choice of activation function. it turned out that activation function other than sigmoid, like relu work much better in deepl learning becaudse it does not saturate and is faster to compute. \n",
    "\n",
    "relu suffers from a problem called dying relu, that is during training some neurons effectively 'die' meaning they stop outputing anythin other than 0. in some cases we find that half of the neurons are dead, especially with high leanring rate. to solve this we use leaky relu. it's defined as max(az,z) parameter a defines how much the relu leaks, it is the slop of z<0, smaller the slop lesser the leak. it can go into long sleep but wakes up after a few layers. \n",
    "\n",
    "in comparision, leaky relu outperform relus. and leaky relu with huge leak perform better than smaller leak relu. randomized leaky relu, where the leak is decided on random also perform fair. paramteric leaky relu where a is authorized to be learned during training. \n",
    "\n",
    "__Exponential Linear Unit (ELU)__\n",
    "\n",
    "\n",
    "exponential linear unit (ELU) outperforms relu variants, with reduced training time.  \n",
    "\n",
    "${ELU}_α (z) = { α(exp (z) − 1) if z < 0  z if z ≥ 0 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ELU activation function looks a lot like the ReLU function, with a few\n",
    "major differences:\n",
    "\n",
    "- It takes on negative values when z < 0, which allows the unit to have an average output closer to 0 and helps alleviate the vanishing gradients problem. - It has a nonzero gradient for z < 0, which avoids the dead neurons problem.\n",
    "- If α is equal to 1 then the function is smooth everywhere, including around z = 0, which helps speed up Gradient Descent since it does not bounce as much to the left and right of z = 0.\n",
    "\n",
    "The main drawback of the ELU activation function is that it is slower to\n",
    "compute than the ReLU function and its variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Scaled ELU activation function__\n",
    "\n",
    "if all hidden layers use the SELU activation function, then the network will selfnormalize: the output of each layer will tend to preserve a mean of 0 and\n",
    "standard deviation of 1 during training, which solves the vanishing/exploding gradients problem. As a result, the SELU activation function often significantly outperforms other activation functions for such neural nets (especially deep ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "keras.layers.Flatten(input_shape=[28, 28]),\n",
    "keras.layers.Dense(100,kernel_initializer = \"he_normal\"),\n",
    "keras.layers.LeakyReLU(alpha = 0.2),\n",
    "keras.layers.Dense(100,activation=\"selu\",kernel_initializer=\"lecun_normal\"),\n",
    "keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6548 - accuracy: 0.7805 - val_loss: 0.4962 - val_accuracy: 0.8258\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4712 - accuracy: 0.8338 - val_loss: 0.4319 - val_accuracy: 0.8526\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4350 - accuracy: 0.8463 - val_loss: 0.4221 - val_accuracy: 0.8532\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4146 - accuracy: 0.8518 - val_loss: 0.3943 - val_accuracy: 0.8622\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3985 - accuracy: 0.8583 - val_loss: 0.3956 - val_accuracy: 0.8608\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3846 - accuracy: 0.8638 - val_loss: 0.3702 - val_accuracy: 0.8746\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3744 - accuracy: 0.8676 - val_loss: 0.3632 - val_accuracy: 0.8744\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3634 - accuracy: 0.8717 - val_loss: 0.3812 - val_accuracy: 0.8624\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3558 - accuracy: 0.8725 - val_loss: 0.3564 - val_accuracy: 0.8752\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3468 - accuracy: 0.8758 - val_loss: 0.3613 - val_accuracy: 0.8734\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3405 - accuracy: 0.8775 - val_loss: 0.3565 - val_accuracy: 0.8736\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3346 - accuracy: 0.8795 - val_loss: 0.3458 - val_accuracy: 0.8778\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3279 - accuracy: 0.8822 - val_loss: 0.3380 - val_accuracy: 0.8794\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3220 - accuracy: 0.8848 - val_loss: 0.3358 - val_accuracy: 0.8794\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3173 - accuracy: 0.8863 - val_loss: 0.3511 - val_accuracy: 0.8738\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3121 - accuracy: 0.8876 - val_loss: 0.3377 - val_accuracy: 0.8818\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3066 - accuracy: 0.8891 - val_loss: 0.3356 - val_accuracy: 0.8774\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3017 - accuracy: 0.8914 - val_loss: 0.3496 - val_accuracy: 0.8778\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2972 - accuracy: 0.8923 - val_loss: 0.3254 - val_accuracy: 0.8812\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2932 - accuracy: 0.8949 - val_loss: 0.3317 - val_accuracy: 0.8830\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2889 - accuracy: 0.8952 - val_loss: 0.3264 - val_accuracy: 0.8836\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2851 - accuracy: 0.8975 - val_loss: 0.3323 - val_accuracy: 0.8816\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2808 - accuracy: 0.8984 - val_loss: 0.3259 - val_accuracy: 0.8848\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2782 - accuracy: 0.9003 - val_loss: 0.3160 - val_accuracy: 0.8856\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2743 - accuracy: 0.9008 - val_loss: 0.3254 - val_accuracy: 0.8838\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2722 - accuracy: 0.9009 - val_loss: 0.3158 - val_accuracy: 0.8850\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2688 - accuracy: 0.9031 - val_loss: 0.3136 - val_accuracy: 0.8866\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2642 - accuracy: 0.9035 - val_loss: 0.3333 - val_accuracy: 0.8802\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2618 - accuracy: 0.9053 - val_loss: 0.3085 - val_accuracy: 0.8888\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2591 - accuracy: 0.9062 - val_loss: 0.3131 - val_accuracy: 0.8908\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/ch_11/keras_relu_selu.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3496 - accuracy: 0.8740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34964653849601746, 0.8740000128746033]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization\n",
    "\n",
    "BN is done before and after a each hidden layer, where the input is zero centered and normalized and output is shifted using the two new paramter vectors per layer, one for scaling and another for shifting. In order to zero-center and normalize the inputs, the algorithm needs to estimate each input’s mean and standard deviation. It does so by evaluating the mean and standard deviation of the input over the current mini-batch (hence the name “Batch Normalization”). Batch Normalization acts like a regularizer, reducing the need for other regularization techniques.\n",
    "\n",
    "\n",
    "Moreover, there is a runtime penalty: the neural network makes slower predictions due to the extra computations required at each layer. Fortunately, it’s often possible to fuse the BN layer with the previous layer, after training, thereby avoiding the runtime penalty. This is done by updating the previous layer’s weights and biases so that it directly produces outputs of the appropriate scale and offset. the training time is slow but the convergence is faster, hence the epoches required for opitmal solution is lesser. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape = [28,28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation = \"elu\", kernel_initializer = \"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation = \"elu\", kernel_initializer = \"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation = \"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##paramters for first bn layer\n",
    "[(var.name, var.trainable) for var in model.layers[1].variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dense/kernel:0', True), ('dense/bias:0', True)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(var.name, var.trainable) for var in model.layers[2].variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization_1/gamma:0', True),\n",
       " ('batch_normalization_1/beta:0', True),\n",
       " ('batch_normalization_1/moving_mean:0', False),\n",
       " ('batch_normalization_1/moving_variance:0', False)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(var.name, var.trainable) for var in model.layers[3].variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 15s 6ms/step - loss: 0.5524 - accuracy: 0.8062 - val_loss: 0.4094 - val_accuracy: 0.8600\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4248 - accuracy: 0.8497 - val_loss: 0.3795 - val_accuracy: 0.8684\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3871 - accuracy: 0.8639 - val_loss: 0.3587 - val_accuracy: 0.8718\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3649 - accuracy: 0.8699 - val_loss: 0.3458 - val_accuracy: 0.8756\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3455 - accuracy: 0.8765 - val_loss: 0.3418 - val_accuracy: 0.8784\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3291 - accuracy: 0.8822 - val_loss: 0.3278 - val_accuracy: 0.8814\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3186 - accuracy: 0.8837 - val_loss: 0.3278 - val_accuracy: 0.8820\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3057 - accuracy: 0.8904 - val_loss: 0.3250 - val_accuracy: 0.8842\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 9s 6ms/step - loss: 0.2971 - accuracy: 0.8923 - val_loss: 0.3214 - val_accuracy: 0.8822\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2898 - accuracy: 0.8938 - val_loss: 0.3169 - val_accuracy: 0.8860\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2797 - accuracy: 0.8976 - val_loss: 0.3234 - val_accuracy: 0.8806\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2715 - accuracy: 0.9018 - val_loss: 0.3186 - val_accuracy: 0.8854\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2655 - accuracy: 0.9029 - val_loss: 0.3134 - val_accuracy: 0.8836\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2570 - accuracy: 0.9056 - val_loss: 0.3118 - val_accuracy: 0.8904\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 9s 6ms/step - loss: 0.2505 - accuracy: 0.9094 - val_loss: 0.3151 - val_accuracy: 0.8878\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2462 - accuracy: 0.9111 - val_loss: 0.3074 - val_accuracy: 0.8886\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2384 - accuracy: 0.9128 - val_loss: 0.3073 - val_accuracy: 0.8912\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2311 - accuracy: 0.9166 - val_loss: 0.3158 - val_accuracy: 0.8850\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2279 - accuracy: 0.9179 - val_loss: 0.3076 - val_accuracy: 0.8884\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2214 - accuracy: 0.9198 - val_loss: 0.3060 - val_accuracy: 0.8906\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 9s 6ms/step - loss: 0.2185 - accuracy: 0.9194 - val_loss: 0.2999 - val_accuracy: 0.8926\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 9s 6ms/step - loss: 0.2139 - accuracy: 0.9224 - val_loss: 0.3154 - val_accuracy: 0.8878\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2085 - accuracy: 0.9230 - val_loss: 0.3092 - val_accuracy: 0.8880\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2037 - accuracy: 0.9259 - val_loss: 0.3109 - val_accuracy: 0.8920\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1997 - accuracy: 0.9269 - val_loss: 0.3208 - val_accuracy: 0.8870\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.1930 - accuracy: 0.9299 - val_loss: 0.3058 - val_accuracy: 0.8938\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.1915 - accuracy: 0.9303 - val_loss: 0.3120 - val_accuracy: 0.8892\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 9s 6ms/step - loss: 0.1880 - accuracy: 0.9315 - val_loss: 0.3166 - val_accuracy: 0.8942\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1842 - accuracy: 0.9336 - val_loss: 0.3100 - val_accuracy: 0.8936\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.1809 - accuracy: 0.9334 - val_loss: 0.3267 - val_accuracy: 0.8912\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3493 - accuracy: 0.8855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3493002951145172, 0.8855000138282776]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\",metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data = (X_val, y_val))\n",
    "model.save('models/ch_11/keras_bn_1.h5')\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add the BN layers before the activation functions, we must remove the activation function from the hidden layers and add them as separate layers after the BN layers. Batch Normalization layer includes one offset parameter per input, we can remove the bias term from the previous layer (just pass use_bias=False when creating it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "keras.layers.Flatten(input_shape=[28, 28]),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.Dense(300, kernel_initializer=\"he_normal\", use_bias=False),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.Activation(\"elu\"),\n",
    "keras.layers.Dense(100, kernel_initializer=\"he_normal\", use_bias=False),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.Activation(\"elu\"),\n",
    "keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 0.5660 - accuracy: 0.8062 - val_loss: 0.4278 - val_accuracy: 0.8516\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4406 - accuracy: 0.8447 - val_loss: 0.3936 - val_accuracy: 0.8676\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4071 - accuracy: 0.8558 - val_loss: 0.3789 - val_accuracy: 0.8704\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 11s 7ms/step - loss: 0.3838 - accuracy: 0.8643 - val_loss: 0.3620 - val_accuracy: 0.8752\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3652 - accuracy: 0.8691 - val_loss: 0.3536 - val_accuracy: 0.8754\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3498 - accuracy: 0.8763 - val_loss: 0.3470 - val_accuracy: 0.8762\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3372 - accuracy: 0.8800 - val_loss: 0.3419 - val_accuracy: 0.8802\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3268 - accuracy: 0.8823 - val_loss: 0.3462 - val_accuracy: 0.8790\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3152 - accuracy: 0.8875 - val_loss: 0.3371 - val_accuracy: 0.8820\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3064 - accuracy: 0.8899 - val_loss: 0.3311 - val_accuracy: 0.8848\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2980 - accuracy: 0.8917 - val_loss: 0.3327 - val_accuracy: 0.8822\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2901 - accuracy: 0.8967 - val_loss: 0.3278 - val_accuracy: 0.8830\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2814 - accuracy: 0.8983 - val_loss: 0.3294 - val_accuracy: 0.8846\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2748 - accuracy: 0.9012 - val_loss: 0.3207 - val_accuracy: 0.8846\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2685 - accuracy: 0.9017 - val_loss: 0.3167 - val_accuracy: 0.8862\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2598 - accuracy: 0.9056 - val_loss: 0.3325 - val_accuracy: 0.8830\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 9s 6ms/step - loss: 0.2550 - accuracy: 0.9078 - val_loss: 0.3164 - val_accuracy: 0.8868\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2510 - accuracy: 0.9091 - val_loss: 0.3267 - val_accuracy: 0.8864\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2438 - accuracy: 0.9111 - val_loss: 0.3299 - val_accuracy: 0.8844\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2398 - accuracy: 0.9138 - val_loss: 0.3161 - val_accuracy: 0.8864\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2331 - accuracy: 0.9158 - val_loss: 0.3137 - val_accuracy: 0.8874\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2313 - accuracy: 0.9167 - val_loss: 0.3128 - val_accuracy: 0.8920\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2247 - accuracy: 0.9179 - val_loss: 0.3205 - val_accuracy: 0.8884\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2192 - accuracy: 0.9206 - val_loss: 0.3136 - val_accuracy: 0.8872\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2179 - accuracy: 0.9207 - val_loss: 0.3180 - val_accuracy: 0.8870\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 9s 6ms/step - loss: 0.2107 - accuracy: 0.9242 - val_loss: 0.3124 - val_accuracy: 0.8904\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2063 - accuracy: 0.9248 - val_loss: 0.3132 - val_accuracy: 0.8922\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2040 - accuracy: 0.9269 - val_loss: 0.3121 - val_accuracy: 0.8898\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.1987 - accuracy: 0.9275 - val_loss: 0.3143 - val_accuracy: 0.8882\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.1949 - accuracy: 0.9301 - val_loss: 0.3295 - val_accuracy: 0.8856\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3542 - accuracy: 0.8816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35423582792282104, 0.881600022315979]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\",metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data = (X_val, y_val))\n",
    "model.save('models/ch_11/keras_bn_2.h5')\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__BN hyperparameters__\n",
    "\n",
    "1. Momentum\n",
    "The BatchNormalization class has quite a few hyperparameters we can tweak. The defaults will usually be fine, but you may occasionally need to tweak the momentum. This hyperparameter is used by the BatchNormalization layer when it updates the exponential moving averages; given a new value v. A good momentum value is typically close to 1; for example, 0.9, 0.99, or 0.999\n",
    "\n",
    "2. Axis\n",
    "it determines which axis should be normalized. It defaults to –1, meaning that by default it will normalize the last axis. \n",
    "\n",
    "### Gradient Clipping\n",
    "\n",
    "Another popular technique to mitigate the exploding gradients problem is to clip the gradients during backpropagation so that they never exceed some threshold. It is often used in RNN, since BN is tricky to use. In Keras, implementing Gradient Clipping is just a matter of setting the clipvalue or clipnorm argument when creating an optimizer.\n",
    "\n",
    "`optimizer = keras.optimizers.SGD(clipvalue=1.0)`\n",
    "`model.compile(loss=\"mse\", optimizer=optimizer)`\n",
    "\n",
    "to ensure that Gradient Clipping does not change the direction of the gradient vector, you should clip by norm by setting clipnorm instead of clipvalue.\n",
    "\n",
    "\n",
    "### Reusing Pretrained Layers\n",
    "\n",
    "we don't usually train the neural network from scratch, we often use the lower layers from a already trained model and build upon it. it's called transfer learning. it reduces the training time and requires very less trianing data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output layer of the original model should usually be replaced because it\n",
    "is most likely not useful at all for the new task, and it may not even have the\n",
    "right number of outputs for the new task. Similarly, the upper hidden layers of the original model are less likely to be as useful as the lower layers, since the high-level features that are most useful for the new task may differ significantly from the ones that were most useful for the original task. we want to find the right number of layers to reuse. The more similar the tasks are, the more layers you want to reuse (starting with the lower layers). For very similar tasks, try keeping all the hidden layers and just replacing\n",
    "the output layer.\n",
    "\n",
    "#### Transfer Learning with Keras\n",
    "\n",
    "load model A and create a new model based on that model’s layers. Let’s reuse all the layers except for the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.load_model(\"models/ch_11/keras_bn_2.h5\")\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we train model_B_on_A, it will also affect model_A. If you want to avoid that, you need to clone model_A before you reuse its layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we could train model_B_on_A for task B, but since the new output layer was initialized randomly it will make large errors (at least during the first few epochs), so there will be large error gradients that may wreck the reused weights. To avoid this, one approach is to freeze the reused layers during the first few epochs, giving the new layer some time to learn reasonable weights. To do this, set every layer’s trainable attribute to False and compile the model. we must always compile your model after you freeze or unfreeze layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B_on_A.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can train the model for a few epochs, then unfreeze the reused layers (which requires compiling the model again) and continue training to fine-tune the reused layers for task B. After unfreezing the reused layers, it is usually a good idea to reduce the learning rate, once again to avoid damaging the reused weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1719/1719 [==============================] - 8s 3ms/step - loss: 0.5014 - accuracy: 0.8434 - val_loss: 0.3561 - val_accuracy: 0.8744\n",
      "Epoch 2/4\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2393 - accuracy: 0.9237 - val_loss: 0.3227 - val_accuracy: 0.8828\n",
      "Epoch 3/4\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2038 - accuracy: 0.9345 - val_loss: 0.3122 - val_accuracy: 0.8880\n",
      "Epoch 4/4\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1860 - accuracy: 0.9403 - val_loss: 0.3090 - val_accuracy: 0.8868\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(X_train, y_train, epochs = 4, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr = 1e-4) ##default is 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B_on_A.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2180 - accuracy: 0.9242 - val_loss: 0.3094 - val_accuracy: 0.8896\n",
      "Epoch 2/16\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2052 - accuracy: 0.9265 - val_loss: 0.3175 - val_accuracy: 0.8860\n",
      "Epoch 3/16\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1971 - accuracy: 0.9300 - val_loss: 0.3120 - val_accuracy: 0.8916\n",
      "Epoch 4/16\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1926 - accuracy: 0.9309 - val_loss: 0.3140 - val_accuracy: 0.8900\n",
      "Epoch 5/16\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1883 - accuracy: 0.9319 - val_loss: 0.3155 - val_accuracy: 0.8914\n",
      "Epoch 6/16\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1845 - accuracy: 0.9336 - val_loss: 0.3188 - val_accuracy: 0.8886\n",
      "Epoch 7/16\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1797 - accuracy: 0.9355 - val_loss: 0.3126 - val_accuracy: 0.8908\n",
      "Epoch 8/16\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1757 - accuracy: 0.9364 - val_loss: 0.3261 - val_accuracy: 0.8884\n",
      "Epoch 9/16\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1735 - accuracy: 0.9384 - val_loss: 0.3150 - val_accuracy: 0.8924\n",
      "Epoch 10/16\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1662 - accuracy: 0.9400 - val_loss: 0.3283 - val_accuracy: 0.8876\n",
      "Epoch 11/16\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.1660 - accuracy: 0.9390 - val_loss: 0.3410 - val_accuracy: 0.8890\n",
      "Epoch 12/16\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1628 - accuracy: 0.9411 - val_loss: 0.3233 - val_accuracy: 0.8920\n",
      "Epoch 13/16\n",
      "1719/1719 [==============================] - 9s 6ms/step - loss: 0.1563 - accuracy: 0.9436 - val_loss: 0.3358 - val_accuracy: 0.8930\n",
      "Epoch 14/16\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1576 - accuracy: 0.9430 - val_loss: 0.3295 - val_accuracy: 0.8890\n",
      "Epoch 15/16\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1543 - accuracy: 0.9449 - val_loss: 0.3263 - val_accuracy: 0.8934\n",
      "Epoch 16/16\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1510 - accuracy: 0.9455 - val_loss: 0.3371 - val_accuracy: 0.8870\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(X_train, y_train, epochs = 16, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3562 - accuracy: 0.8879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35621777176856995, 0.8878999948501587]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we only removed the outer layer and replace with a similar layer so the perofrmance stays the same. \n",
    "\n",
    "transfer learning does not work very well with small dense networks, presumably because small networks learn few patterns, and dense networks learn very specific patterns, which are unlikely to be useful in other tasks. Transfer learning works best with deep convolutional neural networks, which tend to learn feature detectors that are much more general (especially in the lower layers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Pretraining\n",
    "\n",
    "if we cannot find a good amount of training data or a pretrained model we can try using unsupervised pretraining. it's cheaper to grather a lot of training data and then train one unsupervised model like autoencoder or a genrative adversial network. then we can reuse the lower layers of the autoencoder or the lower layers of GAN discriminator add the output layer for the task on top, and fine tune the final network usign supervised learning.\n",
    "\n",
    "#### Pretraining on an Auxiliary Task\n",
    "\n",
    "if we do not have a lot of trainign data, last option is to train a neural network on an auxillary task for which we can easily obtain or generate labeled training data. then reuse the lower layers of the network for the actual task. \n",
    "\n",
    "for nlp task, we can download a corpus of millions of text document and automatically generate labeled data from it.\n",
    "\n",
    "\n",
    "### Faster Optimizers\n",
    "\n",
    "we can speed up the training in 4 ways:\n",
    "- applyign a good initalization strategy\n",
    "- good activation function\n",
    "- using batch normalization\n",
    "- reusing the parts of a pretrained network\n",
    "\n",
    "we can also use a faster optmizer then the regular gradient descent. \n",
    "\n",
    "__Momentum Optimzation__\n",
    "\n",
    "regular gd takes regular steps down the slop, momentum optimizer speeds up on nearing the down slope. Momentum optimization cares a great deal about what previous gradients were: at each iteration, it subtracts the local gradient from the momentum vector m (multiplied by the learning rate η), and it updates the weights by adding this momentum vector. In other words, the gradient is used for acceleration, not for speed.  To simulate some sort of friction mechanism and prevent the momentum from growing too large, the algorithm introduces a new hyperparameter β, called the momentum, which must be set between 0 (high friction) and 1 (no friction). A typical momentum value is 0.9.\n",
    "\n",
    "implementing the momentum in scikit\n",
    "\n",
    "`optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9)`\n",
    "\n",
    "__Nesterov Accelerated Gradient__\n",
    "\n",
    "it works same as momentum, but uses the value of a little farther away to define the momentum. This small tweak works because in general the momentum vector will be pointing in the right direction. NAG is generally faster than regular momentum optimization\n",
    "\n",
    "`optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)`\n",
    "\n",
    "__AdaGrad__\n",
    "\n",
    "AG achieves a correction in direction more towrds the global minimum by scaling down the gradient vector along the steepest dimensions. In short, this algorithm decays the learning rate, but it does so faster for steep dimensions than for dimensions with gentler slopes. This is called an adaptive learning rate. It helps point the resulting updates more directly toward the global optimum.\n",
    "\n",
    "AdaGrad frequently performs well for simple quadratic problems, but it often stops too early when training neural networks. The learning rate gets scaled down so much that the algorithm ends up stopping entirely before reaching the global optimum.\n",
    "\n",
    "\n",
    "__RMSProp__\n",
    "\n",
    "RMSProp fixes the problem of AdaGrad of slowing bit too fast and never converging to global optima. it this by accumulating only the gradients from the most recent iterations (as opposed to all the gradients since the beginning of training). It does so by using exponential decay in the first step. The decay rate β is typically set to 0.9. Yes, it is once again a new hyperparameter, but this default value often works well, so you may not\n",
    "need to tune it at all.\n",
    "\n",
    "`optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9)`\n",
    "\n",
    "__Adam and Nadam Optimization__\n",
    "\n",
    "Adam stands for adaptive moment estimation, combines the ideas of momentum optimization and RMSProp, like momentum optimization. it keeps track of an exponentially decaying average of past gradients. \n",
    "\n",
    "\n",
    "#### TRAINING SPARSE MODELS\n",
    "\n",
    "All the optimization algorithms just presented produce dense models, meaning that most parameters will be nonzero. If you need a blazingly fast model at runtime, or if you need it to take up less memory, you may prefer to end up with a sparse model instead.One easy way to achieve this is to train the model as usual, then get rid of the tiny weights. A better option is to apply strong $ℓ_1$ regularization during training (we will see how later in this chapter), as it pushes the optimizer to zero out as many weights as it can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Rate Scheduling\n",
    "\n",
    "we can do better than a constant lr. if we start with a large learning rate and then reduce it once training stops making fast progress, we can reach a good solution faster than with the optimal constant learning rate. There are many different strategies to reduce the learning rate during training. It can also be beneficial to start with a low learning rate, increase it, then drop it again. These strategies are called learning schedules. \n",
    "\n",
    "__Power scheduling__\n",
    "\n",
    "Set the learning rate to a function of the iteration number t: η(t) = η / (1 + t/s)^c . schedule first drops quickly, then more and more slowly\n",
    "\n",
    "`optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-4)`\n",
    "\n",
    "__Exponential scheduling__\n",
    "\n",
    "Set the learning rate to $η(t) = η {0.1}^{t/s}$ . The learning rate will gradually drop by a factor of 10 every s steps. While power scheduling reduces\n",
    "the learning rate more and more slowly, exponential scheduling keeps slashing it by a factor of 10 every s steps.\n",
    "\n",
    "`def exponential_decay_fn(epoch):\n",
    "        return 0.01 * 0.1**(epoch / 20)`\n",
    "\n",
    "\n",
    "`def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1**(epoch / s)\n",
    "    return exponential_decay_fn`\n",
    "\n",
    "\n",
    "`exponential_decay_fn = exponential_decay(lr0=0.01, s=20)`\n",
    "\n",
    "`lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)`\n",
    "`history = model.fit(X_train_scaled, y_train, [...], callbacks=[lr_scheduler])`\n",
    "\n",
    "__Piecewise constant scheduling__\n",
    "\n",
    "Use a constant learning rate for a number of epochs (e.g., η = 0.1 for 5 epochs), then a smaller learning rate for another number of epochs. \n",
    "\n",
    "`def piecewise_constant_fn(epoch):\n",
    "    if epoch < 5:\n",
    "        return 0.01\n",
    "    elif epoch < 15:\n",
    "        return 0.005\n",
    "    else:\n",
    "        return 0.001`\n",
    "        \n",
    "`lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)`\n",
    "\n",
    "`s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
    "learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
    "optimizer = keras.optimizers.SGD(learning_rate)`\n",
    "\n",
    "__Performance scheduling__\n",
    "\n",
    "Measure the validation error every N steps (just like for early stopping),\n",
    "and reduce the learning rate by a factor of λ when the error stops dropping.\n",
    "\n",
    "__1cycle scheduling__\n",
    "\n",
    "starts by increasing the initial learning rate η , growing linearly up to η halfway through training. Then it decreases the learning rate linearly down to η again during the second half of training, finishing the last few epochs by dropping the rate down by several orders of magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avoiding Overfitting Through Regularization\n",
    "\n",
    "__$ℓ_1$ and $ℓ_2$ Regularization__\n",
    "\n",
    "use ℓ2 regularization to constrain a neural network’s connection weights, and/or ℓ1 regularization for a sparse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_l2 = keras.layers.Dense(100,\n",
    "                          activation =\"elu\",\n",
    "                          kernel_initializer = \"he_normal\",\n",
    "                          kernel_regularizer = keras.regularizers.l2(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_l1 = keras.layers.Dense(100,\n",
    "                          activation =\"elu\",\n",
    "                          kernel_initializer = \"he_normal\",\n",
    "                          kernel_regularizer = keras.regularizers.l1(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_l1_l2 = keras.layers.Dense(100,\n",
    "                          activation =\"elu\",\n",
    "                          kernel_initializer = \"he_normal\",\n",
    "                          kernel_regularizer = keras.regularizers.l1_l2(0.01,0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to apply the same regularizer to all layers in your network, as well as using the same activation function and the same initialization strategy in all hidden layers, we can use functool's partial function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularised_dense = partial(keras.layers.Dense,\n",
    "                            activation = \"elu\",\n",
    "                            kernel_initializer = \"he_normal\",\n",
    "                            kernel_regularizer = keras.regularizers.l2(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([keras.layers.Flatten(input_shape = [28,28]),\n",
    "                                regularised_dense(300),\n",
    "                                regularised_dense(200),\n",
    "                                regularised_dense(10,activation = \"softmax\",kernel_initializer=\"glorot_uniform\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 8.1429 - accuracy: 0.7822 - val_loss: 5.8397 - val_accuracy: 0.8250\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 4.4630 - accuracy: 0.8219 - val_loss: 3.3519 - val_accuracy: 0.8258\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 2.6703 - accuracy: 0.8243 - val_loss: 2.1075 - val_accuracy: 0.8344\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 1.7750 - accuracy: 0.8241 - val_loss: 1.4936 - val_accuracy: 0.8312\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 1.3255 - accuracy: 0.8235 - val_loss: 1.1863 - val_accuracy: 0.8238\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 1.0988 - accuracy: 0.8223 - val_loss: 1.0293 - val_accuracy: 0.8258\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.9831 - accuracy: 0.8214 - val_loss: 0.9332 - val_accuracy: 0.8306\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.9232 - accuracy: 0.8220 - val_loss: 0.8900 - val_accuracy: 0.8342\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.8920 - accuracy: 0.8220 - val_loss: 0.8692 - val_accuracy: 0.8310\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.8755 - accuracy: 0.8214 - val_loss: 0.8529 - val_accuracy: 0.8328\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.8654 - accuracy: 0.8227 - val_loss: 0.8524 - val_accuracy: 0.8294\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.8598 - accuracy: 0.8207 - val_loss: 0.8483 - val_accuracy: 0.8272\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.8564 - accuracy: 0.8219 - val_loss: 0.8490 - val_accuracy: 0.8228\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.8537 - accuracy: 0.8215 - val_loss: 0.8375 - val_accuracy: 0.8310\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.8521 - accuracy: 0.8217 - val_loss: 0.8372 - val_accuracy: 0.8290\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.8513 - accuracy: 0.8218 - val_loss: 0.8352 - val_accuracy: 0.8316\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.8501 - accuracy: 0.8221 - val_loss: 0.8359 - val_accuracy: 0.8302\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.8499 - accuracy: 0.8207 - val_loss: 0.8408 - val_accuracy: 0.8264\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.8488 - accuracy: 0.8214 - val_loss: 0.8324 - val_accuracy: 0.8318\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.8482 - accuracy: 0.8218 - val_loss: 0.8388 - val_accuracy: 0.8282\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.8475 - accuracy: 0.8228 - val_loss: 0.8315 - val_accuracy: 0.8304\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.8472 - accuracy: 0.8219 - val_loss: 0.8340 - val_accuracy: 0.8302\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.8465 - accuracy: 0.8217 - val_loss: 0.8331 - val_accuracy: 0.8302\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.8468 - accuracy: 0.8230 - val_loss: 0.8448 - val_accuracy: 0.8232\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.8463 - accuracy: 0.8214 - val_loss: 0.8386 - val_accuracy: 0.8272\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.8462 - accuracy: 0.8212 - val_loss: 0.8281 - val_accuracy: 0.8328\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.8457 - accuracy: 0.8223 - val_loss: 0.8346 - val_accuracy: 0.8278\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.8458 - accuracy: 0.8222 - val_loss: 0.8277 - val_accuracy: 0.8312\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.8450 - accuracy: 0.8218 - val_loss: 0.8298 - val_accuracy: 0.8304\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.8451 - accuracy: 0.8219 - val_loss: 0.8408 - val_accuracy: 0.8208\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.8788 - accuracy: 0.7998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.878771185874939, 0.7997999787330627]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\",metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data = (X_val, y_val))\n",
    "model.save('models/ch_11/keras_l2_partial.h5')\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Dropout__\n",
    "\n",
    "at every training step, every neuron (including the input neurons, but always excluding the output neurons) has a probability p of being temporarily “dropped out,” meaning it will be entirely ignored during this training step, but it may be active during the next step. The hyperparameter p is called the dropout rate, and it is typically set between 10% and 50%: closer to 20–30% in recurrent neural nets, and closer to 40–50% in convolutional neural networks. After training, neurons don’t get dropped anymore.  In practice, you can usually apply dropout only to the neurons in the top one to three layers (excluding the output layer).\n",
    "\n",
    "\n",
    "To implement dropout using Keras, you can use the keras.layers.Dropout layer. During training, it randomly drops some inputs (setting them to 0) and divides the remaining inputs by the keep N probability. After training, it does nothing at all; it just passes the inputs to the next layer. The following code applies dropout regularization before every Dense layer, using a dropout rate of 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "keras.layers.Flatten(input_shape=[28, 28]),\n",
    "keras.layers.Dropout(rate=0.2),\n",
    "keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "keras.layers.Dropout(rate=0.2),\n",
    "keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "keras.layers.Dropout(rate=0.2),\n",
    "keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.7770 - accuracy: 0.7208 - val_loss: 0.5149 - val_accuracy: 0.8210\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.5797 - accuracy: 0.7919 - val_loss: 0.4661 - val_accuracy: 0.8370\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.5381 - accuracy: 0.8071 - val_loss: 0.4367 - val_accuracy: 0.8498\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.5138 - accuracy: 0.8146 - val_loss: 0.4164 - val_accuracy: 0.8550\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4985 - accuracy: 0.8203 - val_loss: 0.4132 - val_accuracy: 0.8570\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4880 - accuracy: 0.8228 - val_loss: 0.4000 - val_accuracy: 0.8602\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4742 - accuracy: 0.8292 - val_loss: 0.4050 - val_accuracy: 0.8578\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4660 - accuracy: 0.8298 - val_loss: 0.3924 - val_accuracy: 0.8616\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4600 - accuracy: 0.8319 - val_loss: 0.3839 - val_accuracy: 0.8650\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4545 - accuracy: 0.8349 - val_loss: 0.3782 - val_accuracy: 0.8656\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4501 - accuracy: 0.8356 - val_loss: 0.3784 - val_accuracy: 0.8646\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4441 - accuracy: 0.8388 - val_loss: 0.3707 - val_accuracy: 0.8698\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4410 - accuracy: 0.8384 - val_loss: 0.3687 - val_accuracy: 0.8706\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4335 - accuracy: 0.8409 - val_loss: 0.3688 - val_accuracy: 0.8688\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4302 - accuracy: 0.8430 - val_loss: 0.3647 - val_accuracy: 0.8686\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4255 - accuracy: 0.8449 - val_loss: 0.3591 - val_accuracy: 0.8730\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4255 - accuracy: 0.8443 - val_loss: 0.3593 - val_accuracy: 0.8678\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4212 - accuracy: 0.8458 - val_loss: 0.3592 - val_accuracy: 0.8688\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4176 - accuracy: 0.8471 - val_loss: 0.3525 - val_accuracy: 0.8734\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4148 - accuracy: 0.8479 - val_loss: 0.3503 - val_accuracy: 0.8768\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4127 - accuracy: 0.8479 - val_loss: 0.3506 - val_accuracy: 0.8752\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4076 - accuracy: 0.8491 - val_loss: 0.3455 - val_accuracy: 0.8736\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4067 - accuracy: 0.8493 - val_loss: 0.3481 - val_accuracy: 0.8760\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4072 - accuracy: 0.8515 - val_loss: 0.3421 - val_accuracy: 0.8744\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4035 - accuracy: 0.8503 - val_loss: 0.3382 - val_accuracy: 0.8790\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3999 - accuracy: 0.8514 - val_loss: 0.3391 - val_accuracy: 0.8786\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3988 - accuracy: 0.8535 - val_loss: 0.3375 - val_accuracy: 0.8768\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3971 - accuracy: 0.8535 - val_loss: 0.3350 - val_accuracy: 0.8784\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3957 - accuracy: 0.8523 - val_loss: 0.3352 - val_accuracy: 0.8790\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3943 - accuracy: 0.8551 - val_loss: 0.3320 - val_accuracy: 0.8796\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3715 - accuracy: 0.8629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37152379751205444, 0.8629000186920166]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\",metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data = (X_val, y_val))\n",
    "model.save('models/ch_11/keras_dropout.h5')\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since dropout is only active during training, comparing the training loss and the validation loss can be misleading. In particular, a model may be overfitting the training set and yet have similar training and validation losses. So make sure to evaluate the training loss without dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3236 - accuracy: 0.8808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32357415556907654, 0.8807818293571472]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if the model is overfitting, increase the dropout rate\n",
    "- if the model is underfitting, decrease the dropout rate\n",
    "\n",
    "Dropout does tend to significantly slow down convergence, but it usually\n",
    "results in a much better model when tuned properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Monte Carlo (MC) Dropout__\n",
    "\n",
    "can boost the performance of any trained dropout model without having to retrain it or even modify it at all, provides a much better measure of the model’s uncertainty, and is also amazingly simple to implement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_probas = np.stack([model(X_test, training=True) for sample in range(100)])\n",
    "y_proba = y_probas.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just make 100 predictions over the test set, setting training=True to ensure that the Dropout layer is active, and stack the predictions. Since dropout is active, all the predictions will be different. Averaging over multiple predictions with dropout on gives us a Monte Carlo estimate that is generally more reliable than the result of a single prediction with dropout off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.12, 0.  , 0.84]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(model.predict(X_test[:1]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.38, 0.  , 0.57]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.08, 0.  , 0.86]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.06, 0.  , 0.9 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.09, 0.  , 0.87]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.12, 0.  , 0.82]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.31, 0.  , 0.65]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.18, 0.  , 0.77]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.07, 0.02, 0.8 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.1 , 0.  , 0.85]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.05, 0.  , 0.88]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.13, 0.  , 0.82]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.78, 0.  , 0.17]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.02, 0.  , 0.85]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.35, 0.  , 0.54]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.15, 0.  , 0.84]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.03, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.29, 0.  , 0.7 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.4 , 0.  , 0.54]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.06, 0.  , 0.91]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.02, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.53, 0.  , 0.01, 0.  , 0.46]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.02, 0.  , 0.92]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.35, 0.  , 0.59]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.06, 0.  , 0.92]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.36, 0.  , 0.58]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.33, 0.  , 0.6 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.13, 0.  , 0.83]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.36, 0.  , 0.6 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.06, 0.  , 0.91]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.34, 0.  , 0.62]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.51, 0.  , 0.4 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.14, 0.  , 0.83]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.11, 0.  , 0.86]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.53, 0.  , 0.37]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.23, 0.  , 0.21, 0.01, 0.55]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.26, 0.  , 0.73]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.14, 0.  , 0.04, 0.  , 0.82]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.26, 0.  , 0.65]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.18, 0.  , 0.73]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.21, 0.  , 0.74]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.01, 0.01, 0.87]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.32, 0.  , 0.59]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.91]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.08, 0.  , 0.91]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.57, 0.  , 0.26, 0.  , 0.17]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.39, 0.  , 0.56]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.13, 0.  , 0.77]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.28, 0.01, 0.69]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.18, 0.  , 0.79]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.09, 0.  , 0.88]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.28, 0.  , 0.36, 0.  , 0.36]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.03, 0.  , 0.91]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.52, 0.  , 0.13, 0.01, 0.34]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.02, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.2 , 0.02, 0.77]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.59, 0.  , 0.01, 0.02, 0.38]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.37, 0.  , 0.04, 0.  , 0.6 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.04, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.42, 0.  , 0.5 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.26, 0.  , 0.7 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.45, 0.  , 0.49]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.07, 0.01, 0.79]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.14, 0.  , 0.04, 0.  , 0.82]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.3 , 0.  , 0.04, 0.  , 0.66]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.27, 0.  , 0.17, 0.  , 0.55]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.14, 0.  , 0.81]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.34, 0.  , 0.42, 0.  , 0.23]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.09, 0.  , 0.87]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.04, 0.  , 0.89]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.18, 0.  , 0.4 , 0.  , 0.43]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.61, 0.01, 0.34]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.01, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.07, 0.  , 0.91]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.11, 0.  , 0.84]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.37, 0.  , 0.4 , 0.01, 0.22]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.78, 0.  , 0.06, 0.01, 0.16]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.02, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.36, 0.  , 0.3 , 0.  , 0.34]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.27, 0.  , 0.69]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.04, 0.  , 0.88]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.36, 0.  , 0.18, 0.01, 0.45]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.2 , 0.  , 0.76]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.67, 0.  , 0.02, 0.  , 0.31]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.38, 0.  , 0.58]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.26, 0.  , 0.08, 0.  , 0.66]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.14, 0.01, 0.81]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.34, 0.  , 0.64]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.02, 0.01, 0.94]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.88]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.14, 0.  , 0.17, 0.  , 0.69]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.5 , 0.  , 0.44]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.07, 0.  , 0.8 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.24, 0.  , 0.69]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.41, 0.  , 0.01, 0.  , 0.58]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.22, 0.  , 0.73]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.57, 0.  , 0.39]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.15, 0.  , 0.71]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.56, 0.  , 0.04, 0.  , 0.4 ]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_probas[:, :1], 2) ##with dropout active it's not sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.19, 0.  , 0.69]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_proba[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.16, 0.  , 0.16, 0.  , 0.21]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_std = y_probas.std(axis=0)\n",
    "np.round(y_std[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8645\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(y_proba, axis=1) \n",
    "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "print(accuracy) ##increased from 86.2 to 86.5 using mc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The number of Monte Carlo samples you use (100 in this example) is a hyperparameter you can tweak. The higher it is, the more accurate the predictions and their uncertainty estimates will be. However, if you double it, inference time will also be doubled. Moreover, above a certain number of samples, you will notice little improvement. So your job is to find the right trade-off between latency and accuracy, depending on you  application "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Max-Norm Regularization__\n",
    "\n",
    "for each neuron, it constrains the weights w of the incoming connections such that ∥ w ∥ ≤ r, where r is the maxnorm hyperparameter and ∥ · ∥ is the ℓ2 norm. Max-norm regularization does not add a regularization loss term to the overall loss function. Reducing r increases the amount of regularization and helps reduce overfitting. Max-norm regularization can also help alleviate the unstable gradients problems.\n",
    "\n",
    "`keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\", kernel_constraint=keras.constraints.max_norm(1.))`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "__1. Is it OK to initialize all the weights to the same value as long as that value is selected randomly using He initialization?__\n",
    "\n",
    "It's important to have a random initialization, but it's also important to maintain assymetry in the weights. Hence, same weights cannot be assigned. \n",
    "\n",
    "__2. Is it OK to initialize the bias terms to 0?__\n",
    "\n",
    "it would not make any difference\n",
    "\n",
    "__3. Name three advantages of the SELU activation function over ReLU.__\n",
    "\n",
    "- non zero derivative\n",
    "- negative values\n",
    "- can ensure the model is normalized avoiding gradient issues\n",
    "\n",
    "__4. In which cases would you want to use each of the following activation functions: SELU, leaky ReLU (and its variants), ReLU, tanh, logistic, and softmax?__\n",
    "\n",
    "- SELU: better then relu, faster, self normalizing and helps in gradient issues\n",
    "- Leaky ReLU: help in gradient issues, faster\n",
    "- ReLU: vanilla option, good for simpler nn\n",
    "- Tanh: output between -1 and 1\n",
    "- Logistic: for predicting probabilites\n",
    "- Softmax: when the output is required to be only positive values and for multiclass outputs\n",
    "\n",
    "__5. What may happen if you set the momentum hyperparameter too close to 1 (e.g., 0.99999) when using an SGD optimizer?__\n",
    "\n",
    "it might accelerate too much and skip the global minima without slowing.\n",
    "\n",
    "__6. Name three ways you can produce a sparse model.__\n",
    "\n",
    "- train model normally, zero out tiny weights\n",
    "- l1 regularization\n",
    "- model optimization toolkit\n",
    "\n",
    "__7. Does dropout slow down training? Does it slow down inference (i.e., making predictions on new instances)? What about MC Dropout?__\n",
    "\n",
    "- dropout slows down the training, roughly by 2\n",
    "- MC dropout is like dropout during training, and also applied after training during inference, it may run inference 10 or more times, hence slows down more than normal droupout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__8. Practice training a deep neural network on the CIFAR10 image dataset:__\n",
    "\n",
    "\n",
    "__a. Build a DNN with 20 hidden layers of 100 neurons each (that’s too many, but it’s the point of this exercise). Use He initialization and the ELU activation function.__\n",
    "\n",
    "__b. Using Nadam optimization and early stopping, train the network on the CIFAR10 dataset. You can load it with keras.datasets.cifar10.load_ data(). The dataset is composed of 60,000 32 × 32–pixel color images (50,000 for training, 10,000 for testing) with 10 classes, so you’ll need a softmax output layer with 10 neurons. Remember to search for the right learning rate each time you change the model’s architecture or hyperparameters.__\n",
    "\n",
    "__c. Now try adding Batch Normalization and compare the learning curves: Is it converging faster than before? Does it produce a better model? How does it affect training speed?__\n",
    "\n",
    "__d. Try replacing Batch Normalization with SELU, and make the necessary adjustements to ensure the network selfnormalizes (i.e., standardize the input features, use LeCun normal initialization, make sure the DNN contains only a sequence of dense layers, etc.).__\n",
    "\n",
    "__e. Try regularizing the model with alpha dropout. Then, without retraining your model, see if you can achieve better accuracy using MC Dropout.__\n",
    "\n",
    "\n",
    "__f. Retrain your model using 1cycle scheduling and see if it improves training speed and model accuracy.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##importing libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 488s 3us/step\n",
      "170508288/170498071 [==============================] - 488s 3us/step\n"
     ]
    }
   ],
   "source": [
    "##loading dataset\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 5000\n",
    "X_val, X_train, y_val, y_train = X_train[:x,],X_train[x:,], y_train[:x],y_train[x:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n",
      "(5000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 1)\n",
      "(10000, 1)\n",
      "(5000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16ce080c820>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[1]) ##looks like a horse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Build a DNN with 20 hidden layers of 100 neurons each (that’s too many, but it’s the point of this exercise). Use He initialization and the ELU activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_avg_init = keras.initializers.VarianceScaling(scale=2, mode='fan_avg', distribution = \"uniform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layers(model, n_neurons = 100, n_layers_hidden = 20, activation_func = \"elu\", init = \"he_normal\"):\n",
    "    for layer in range(0,n_layers_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation = activation_func, kernel_initializer = init ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Flatten(input_shape = [32,32,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_layers(model,100,20,\"elu\", \"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "##final layer\n",
    "model.add(keras.layers.Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Flatten at 0x16cfdffc9a0>,\n",
       " <keras.layers.core.Dense at 0x16ce1da38b0>,\n",
       " <keras.layers.core.Dense at 0x16cf47ac340>,\n",
       " <keras.layers.core.Dense at 0x16ce1e5e940>,\n",
       " <keras.layers.core.Dense at 0x16ce1da88b0>,\n",
       " <keras.layers.core.Dense at 0x16ce1da87f0>,\n",
       " <keras.layers.core.Dense at 0x16ce1db3820>,\n",
       " <keras.layers.core.Dense at 0x16ce1db9430>,\n",
       " <keras.layers.core.Dense at 0x16ce1db94f0>,\n",
       " <keras.layers.core.Dense at 0x16ce1db3580>,\n",
       " <keras.layers.core.Dense at 0x16ce1db3700>,\n",
       " <keras.layers.core.Dense at 0x16cfdffce20>,\n",
       " <keras.layers.core.Dense at 0x16ce1dc2e50>,\n",
       " <keras.layers.core.Dense at 0x16ce1db3d60>,\n",
       " <keras.layers.core.Dense at 0x16ce1dd71f0>,\n",
       " <keras.layers.core.Dense at 0x16ce1dd7f70>,\n",
       " <keras.layers.core.Dense at 0x16ce1db35e0>,\n",
       " <keras.layers.core.Dense at 0x16ce1db3970>,\n",
       " <keras.layers.core.Dense at 0x16ce1ddfdf0>,\n",
       " <keras.layers.core.Dense at 0x16ce1dd1a60>,\n",
       " <keras.layers.core.Dense at 0x16ce1dd1c40>,\n",
       " <keras.layers.core.Dense at 0x16ce1dee820>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Using Nadam optimization and early stopping, train the network on the CIFAR10 dataset. You can load it with keras.datasets.cifar10.load_ data(). The dataset is composed of 60,000 32 × 32–pixel color images (50,000 for training, 10,000 for testing) with 10 classes, so you’ll need a softmax output layer with 10 neurons. Remember to search for the right learning rate each time you change the model’s architecture or hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-5\n",
    "opt = tf.keras.optimizers.Nadam(learning_rate=lr)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"models/ch_11/ex_early_stopping_8b.h5\", save_best_only=True)\n",
    "es_cb = keras.callbacks.EarlyStopping(patience = 20, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer= opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 39s 23ms/step - loss: 6.0083 - accuracy: 0.1620 - val_loss: 2.4514 - val_accuracy: 0.1750\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 32s 23ms/step - loss: 2.0889 - accuracy: 0.2404 - val_loss: 2.1304 - val_accuracy: 0.2310\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 32s 22ms/step - loss: 1.9550 - accuracy: 0.2797 - val_loss: 1.9327 - val_accuracy: 0.3024\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 30s 21ms/step - loss: 1.8742 - accuracy: 0.3145 - val_loss: 1.9241 - val_accuracy: 0.3024\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 32s 23ms/step - loss: 1.8093 - accuracy: 0.3424 - val_loss: 1.7871 - val_accuracy: 0.3462\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 34s 24ms/step - loss: 1.7554 - accuracy: 0.3631 - val_loss: 1.7155 - val_accuracy: 0.3776\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 49s 35ms/step - loss: 1.7094 - accuracy: 0.3812 - val_loss: 1.7480 - val_accuracy: 0.3654\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 48s 34ms/step - loss: 1.6761 - accuracy: 0.3957 - val_loss: 1.6814 - val_accuracy: 0.3826\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 50s 35ms/step - loss: 1.6430 - accuracy: 0.4106 - val_loss: 1.6940 - val_accuracy: 0.3910\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 51s 36ms/step - loss: 1.6167 - accuracy: 0.4161 - val_loss: 1.6320 - val_accuracy: 0.4132\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 1.5964 - accuracy: 0.4255 - val_loss: 1.6392 - val_accuracy: 0.4166\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 35s 25ms/step - loss: 1.5746 - accuracy: 0.4326 - val_loss: 1.6499 - val_accuracy: 0.4004\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 31s 22ms/step - loss: 1.5540 - accuracy: 0.4418 - val_loss: 1.6347 - val_accuracy: 0.4136\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 35s 25ms/step - loss: 1.5354 - accuracy: 0.4476 - val_loss: 1.6249 - val_accuracy: 0.4250\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 31s 22ms/step - loss: 1.5232 - accuracy: 0.4537 - val_loss: 1.5989 - val_accuracy: 0.4236\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 30s 21ms/step - loss: 1.5019 - accuracy: 0.4603 - val_loss: 1.5991 - val_accuracy: 0.4240\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 31s 22ms/step - loss: 1.4895 - accuracy: 0.4658 - val_loss: 1.5821 - val_accuracy: 0.4320\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 33s 24ms/step - loss: 1.4752 - accuracy: 0.4718 - val_loss: 1.5743 - val_accuracy: 0.4374\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 32s 23ms/step - loss: 1.4648 - accuracy: 0.4729 - val_loss: 1.5891 - val_accuracy: 0.4376\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 31s 22ms/step - loss: 1.4492 - accuracy: 0.4790 - val_loss: 1.5593 - val_accuracy: 0.4462\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 32s 23ms/step - loss: 1.4377 - accuracy: 0.4831 - val_loss: 1.5600 - val_accuracy: 0.4370\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 29s 20ms/step - loss: 1.4227 - accuracy: 0.4886 - val_loss: 1.5440 - val_accuracy: 0.4586\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 31s 22ms/step - loss: 1.4119 - accuracy: 0.4946 - val_loss: 1.5395 - val_accuracy: 0.4500\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 32s 23ms/step - loss: 1.4025 - accuracy: 0.4967 - val_loss: 1.5317 - val_accuracy: 0.45320s - los\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 31s 22ms/step - loss: 1.3896 - accuracy: 0.5012 - val_loss: 1.5258 - val_accuracy: 0.4538\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 31s 22ms/step - loss: 1.3812 - accuracy: 0.5036 - val_loss: 1.5482 - val_accuracy: 0.4568\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 31s 22ms/step - loss: 1.3680 - accuracy: 0.5094 - val_loss: 1.6033 - val_accuracy: 0.4458\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 30s 22ms/step - loss: 1.3560 - accuracy: 0.5136 - val_loss: 1.5259 - val_accuracy: 0.4584\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 1.3471 - accuracy: 0.5161 - val_loss: 1.5335 - val_accuracy: 0.4634\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 31s 22ms/step - loss: 1.3368 - accuracy: 0.5227 - val_loss: 1.5909 - val_accuracy: 0.4398\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 30s 21ms/step - loss: 1.3301 - accuracy: 0.5222 - val_loss: 1.5236 - val_accuracy: 0.4622\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 33s 23ms/step - loss: 1.3217 - accuracy: 0.5257 - val_loss: 1.5615 - val_accuracy: 0.4504\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 31s 22ms/step - loss: 1.3092 - accuracy: 0.5315 - val_loss: 1.5217 - val_accuracy: 0.4624\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 35s 25ms/step - loss: 1.3050 - accuracy: 0.5323 - val_loss: 1.5411 - val_accuracy: 0.4618\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 25s 18ms/step - loss: 1.2934 - accuracy: 0.5358 - val_loss: 1.5072 - val_accuracy: 0.4674\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.2825 - accuracy: 0.5367 - val_loss: 1.5579 - val_accuracy: 0.4568\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.2740 - accuracy: 0.5434 - val_loss: 1.5559 - val_accuracy: 0.4678\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 25s 18ms/step - loss: 1.2668 - accuracy: 0.5453 - val_loss: 1.5316 - val_accuracy: 0.4544\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.2573 - accuracy: 0.5457 - val_loss: 1.5353 - val_accuracy: 0.4718\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.2497 - accuracy: 0.5512 - val_loss: 1.5524 - val_accuracy: 0.4568\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.2442 - accuracy: 0.5526 - val_loss: 1.5180 - val_accuracy: 0.4612\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 22s 15ms/step - loss: 1.2331 - accuracy: 0.5569 - val_loss: 1.5778 - val_accuracy: 0.4576\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 20s 15ms/step - loss: 1.2268 - accuracy: 0.5607 - val_loss: 1.5632 - val_accuracy: 0.4576\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.2182 - accuracy: 0.5620 - val_loss: 1.5276 - val_accuracy: 0.4642\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.2119 - accuracy: 0.5662 - val_loss: 1.5132 - val_accuracy: 0.4772\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.2045 - accuracy: 0.5674 - val_loss: 1.5331 - val_accuracy: 0.4672\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.1979 - accuracy: 0.5711 - val_loss: 1.5242 - val_accuracy: 0.4744\n",
      "Epoch 48/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.1874 - accuracy: 0.5750 - val_loss: 1.5706 - val_accuracy: 0.4612\n",
      "Epoch 49/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.1794 - accuracy: 0.5776 - val_loss: 1.5750 - val_accuracy: 0.4634\n",
      "Epoch 50/100\n",
      "1407/1407 [==============================] - 20s 15ms/step - loss: 1.1771 - accuracy: 0.5793 - val_loss: 1.5295 - val_accuracy: 0.4694\n",
      "Epoch 51/100\n",
      "1407/1407 [==============================] - 25s 18ms/step - loss: 1.1684 - accuracy: 0.5812 - val_loss: 1.5418 - val_accuracy: 0.4732\n",
      "Epoch 52/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.1572 - accuracy: 0.5833 - val_loss: 1.5915 - val_accuracy: 0.4708\n",
      "Epoch 53/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.1538 - accuracy: 0.5863 - val_loss: 1.5568 - val_accuracy: 0.4762\n",
      "Epoch 54/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.1461 - accuracy: 0.5889 - val_loss: 1.5598 - val_accuracy: 0.4734\n",
      "Epoch 55/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.1406 - accuracy: 0.5903 - val_loss: 1.5572 - val_accuracy: 0.4696\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val),callbacks=[checkpoint_cb,es_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4927 - accuracy: 0.4707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.492699384689331, 0.4706999957561493]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('models/ch_11/ex_final_model_8b.h5')\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curves(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 2) # set the vertical range to [0-1]\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Now try adding Batch Normalization and compare the learning curves: Is it converging faster than before? Does it produce a better model? How does it affect training speed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layers_bn(model, n_neurons = 100, n_layers_hidden = 20, activation_func = \"elu\", init = \"he_normal\"):\n",
    "    for layer in range(0,n_layers_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, kernel_initializer = init ))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(keras.layers.Activation(activation = activation_func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32,32,3]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "add_layers_bn(model,100,20,\"elu\",\"he_normal\")\n",
    "model.add(keras.layers.Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-5\n",
    "opt = tf.keras.optimizers.Nadam(learning_rate=lr)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"models/ch_11/ex_early_stopping_8c.h5\", save_best_only=True)\n",
    "es_cb = keras.callbacks.EarlyStopping(patience = 20, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer= opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 49s 27ms/step - loss: 2.0734 - accuracy: 0.2588 - val_loss: 1.7889 - val_accuracy: 0.3548\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 40s 29ms/step - loss: 1.8048 - accuracy: 0.3522 - val_loss: 1.6772 - val_accuracy: 0.3922\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 36s 26ms/step - loss: 1.7121 - accuracy: 0.3873 - val_loss: 1.6002 - val_accuracy: 0.4282\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 52s 37ms/step - loss: 1.6480 - accuracy: 0.4095 - val_loss: 1.5591 - val_accuracy: 0.4416\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 43s 30ms/step - loss: 1.6064 - accuracy: 0.4265 - val_loss: 1.5271 - val_accuracy: 0.4492\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 1.5632 - accuracy: 0.4430 - val_loss: 1.4965 - val_accuracy: 0.4636\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 43s 30ms/step - loss: 1.5279 - accuracy: 0.4542 - val_loss: 1.4638 - val_accuracy: 0.4760\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 38s 27ms/step - loss: 1.5079 - accuracy: 0.4620 - val_loss: 1.4577 - val_accuracy: 0.4800\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 40s 28ms/step - loss: 1.4847 - accuracy: 0.4698 - val_loss: 1.4327 - val_accuracy: 0.4904\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 1.4538 - accuracy: 0.4823 - val_loss: 1.4367 - val_accuracy: 0.4848\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 38s 27ms/step - loss: 1.4311 - accuracy: 0.4889 - val_loss: 1.4173 - val_accuracy: 0.4966\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 38s 27ms/step - loss: 1.4174 - accuracy: 0.4944 - val_loss: 1.4123 - val_accuracy: 0.5012\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 38s 27ms/step - loss: 1.4013 - accuracy: 0.4991 - val_loss: 1.3893 - val_accuracy: 0.5054\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 39s 28ms/step - loss: 1.3889 - accuracy: 0.5058 - val_loss: 1.3938 - val_accuracy: 0.5032\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 38s 27ms/step - loss: 1.3683 - accuracy: 0.5122 - val_loss: 1.3736 - val_accuracy: 0.5196\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 39s 28ms/step - loss: 1.3548 - accuracy: 0.5190 - val_loss: 1.3862 - val_accuracy: 0.5160\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 1.3433 - accuracy: 0.5243 - val_loss: 1.3913 - val_accuracy: 0.5074\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 1.3320 - accuracy: 0.5246 - val_loss: 1.3834 - val_accuracy: 0.5064\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 38s 27ms/step - loss: 1.3162 - accuracy: 0.5304 - val_loss: 1.3885 - val_accuracy: 0.5092\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 37s 27ms/step - loss: 1.3072 - accuracy: 0.5339 - val_loss: 1.3713 - val_accuracy: 0.5118\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 39s 28ms/step - loss: 1.2983 - accuracy: 0.5368 - val_loss: 1.3771 - val_accuracy: 0.5130\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 39s 27ms/step - loss: 1.2830 - accuracy: 0.5423 - val_loss: 1.3727 - val_accuracy: 0.5184\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 39s 28ms/step - loss: 1.2758 - accuracy: 0.5447 - val_loss: 1.3721 - val_accuracy: 0.5156\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 40s 28ms/step - loss: 1.2679 - accuracy: 0.5474 - val_loss: 1.3652 - val_accuracy: 0.5194\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 50s 35ms/step - loss: 1.2576 - accuracy: 0.5511 - val_loss: 1.3707 - val_accuracy: 0.5164\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 57s 41ms/step - loss: 1.2452 - accuracy: 0.5572 - val_loss: 1.3726 - val_accuracy: 0.5206\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 48s 34ms/step - loss: 1.2366 - accuracy: 0.5590 - val_loss: 1.3688 - val_accuracy: 0.5268\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 59s 42ms/step - loss: 1.2263 - accuracy: 0.5638 - val_loss: 1.3669 - val_accuracy: 0.5192\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 66s 47ms/step - loss: 1.2171 - accuracy: 0.5647 - val_loss: 1.3821 - val_accuracy: 0.5214\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 46s 33ms/step - loss: 1.2139 - accuracy: 0.5675 - val_loss: 1.3746 - val_accuracy: 0.5166\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 42s 30ms/step - loss: 1.2054 - accuracy: 0.5706 - val_loss: 1.3783 - val_accuracy: 0.5228\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 1.1913 - accuracy: 0.5736 - val_loss: 1.3750 - val_accuracy: 0.5242\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 1.1869 - accuracy: 0.5791 - val_loss: 1.3759 - val_accuracy: 0.5194\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 1.1854 - accuracy: 0.5761 - val_loss: 1.3664 - val_accuracy: 0.5228\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 26s 18ms/step - loss: 1.1764 - accuracy: 0.5809 - val_loss: 1.3942 - val_accuracy: 0.5206\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 25s 18ms/step - loss: 1.1598 - accuracy: 0.5895 - val_loss: 1.3714 - val_accuracy: 0.5262\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 26s 18ms/step - loss: 1.1541 - accuracy: 0.5878 - val_loss: 1.3802 - val_accuracy: 0.5248\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 26s 18ms/step - loss: 1.1514 - accuracy: 0.5894 - val_loss: 1.3768 - val_accuracy: 0.5258\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 25s 18ms/step - loss: 1.1460 - accuracy: 0.5915 - val_loss: 1.3748 - val_accuracy: 0.5226\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 26s 18ms/step - loss: 1.1356 - accuracy: 0.5952 - val_loss: 1.3791 - val_accuracy: 0.5236\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 26s 18ms/step - loss: 1.1313 - accuracy: 0.5992 - val_loss: 1.3696 - val_accuracy: 0.5298\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 49s 35ms/step - loss: 1.1193 - accuracy: 0.6025 - val_loss: 1.3889 - val_accuracy: 0.5194\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 40s 28ms/step - loss: 1.1170 - accuracy: 0.6022 - val_loss: 1.3699 - val_accuracy: 0.5318\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 26s 18ms/step - loss: 1.1088 - accuracy: 0.6051 - val_loss: 1.3893 - val_accuracy: 0.5226\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val),callbacks=[checkpoint_cb,es_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3653 - accuracy: 0.5157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.365283489227295, 0.5156999826431274]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('models/ch_11/ex_final_model_8c.h5')\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- is it converging faster than before? yes, it can be seen from the loss curve\n",
    "- Does it produce a better model?  yes, the accuracy on test set increased from 47% to 51%\n",
    "- How does it affect training speed? it's almost similar or slight higer, earlier each epoch took 30-31ms, now it took 30-35ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Try replacing Batch Normalization with SELU, and make the necessary adjustements to ensure the network selfnormalizes (i.e., standardize the input features, use LeCun normal initialization, make sure the DNN contains only a sequence of dense layers, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32,32,3]))\n",
    "add_layers(model,100,20,\"selu\",\"lecun_normal\")\n",
    "model.add(keras.layers.Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-5\n",
    "opt = tf.keras.optimizers.Nadam(learning_rate=lr)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"models/ch_11/ex_early_stopping_8d.h5\", save_best_only=True)\n",
    "es_cb = keras.callbacks.EarlyStopping(patience = 20, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer= opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = (X_train - X_train.mean(axis=0)) / X_train.std(axis=0)\n",
    "X_val_scaled = (X_val - X_val.mean(axis=0)) / X_val.std(axis=0)\n",
    "X_test_scaled =  (X_test - X_test.mean(axis=0)) / X_test.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 43s 20ms/step - loss: 1.8795 - accuracy: 0.3337 - val_loss: 1.7030 - val_accuracy: 0.3856\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.6503 - accuracy: 0.4127 - val_loss: 1.6309 - val_accuracy: 0.4128\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 20s 15ms/step - loss: 1.5457 - accuracy: 0.4494 - val_loss: 1.5639 - val_accuracy: 0.4412\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.4721 - accuracy: 0.4768 - val_loss: 1.5452 - val_accuracy: 0.4600\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.4117 - accuracy: 0.4990 - val_loss: 1.5427 - val_accuracy: 0.4582\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.3593 - accuracy: 0.5166 - val_loss: 1.4933 - val_accuracy: 0.4744\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.3105 - accuracy: 0.5334 - val_loss: 1.4922 - val_accuracy: 0.4816\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.2704 - accuracy: 0.5484 - val_loss: 1.4906 - val_accuracy: 0.4776\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.2291 - accuracy: 0.5634 - val_loss: 1.4868 - val_accuracy: 0.4814\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.1942 - accuracy: 0.5766 - val_loss: 1.4862 - val_accuracy: 0.4890\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.1567 - accuracy: 0.5884 - val_loss: 1.4843 - val_accuracy: 0.4874\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.1267 - accuracy: 0.6006 - val_loss: 1.4852 - val_accuracy: 0.4938\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.0929 - accuracy: 0.6110 - val_loss: 1.5134 - val_accuracy: 0.4862\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.0620 - accuracy: 0.6248 - val_loss: 1.5029 - val_accuracy: 0.4966\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.0306 - accuracy: 0.6358 - val_loss: 1.5364 - val_accuracy: 0.4916\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.0022 - accuracy: 0.6460 - val_loss: 1.5424 - val_accuracy: 0.4886\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 0.9703 - accuracy: 0.6578 - val_loss: 1.5475 - val_accuracy: 0.4842\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 0.9473 - accuracy: 0.6654 - val_loss: 1.5658 - val_accuracy: 0.4860\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 0.9172 - accuracy: 0.6749 - val_loss: 1.5973 - val_accuracy: 0.4880\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 0.8913 - accuracy: 0.6855 - val_loss: 1.5997 - val_accuracy: 0.4912\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 0.8663 - accuracy: 0.6966 - val_loss: 1.6550 - val_accuracy: 0.4830\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 0.8397 - accuracy: 0.7034 - val_loss: 1.6640 - val_accuracy: 0.4778\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 0.8161 - accuracy: 0.7125 - val_loss: 1.6819 - val_accuracy: 0.4878\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 0.7888 - accuracy: 0.7220 - val_loss: 1.7087 - val_accuracy: 0.4830\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 0.7663 - accuracy: 0.7309 - val_loss: 1.7581 - val_accuracy: 0.4808\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 0.7423 - accuracy: 0.7395 - val_loss: 1.7792 - val_accuracy: 0.4816\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 0.7169 - accuracy: 0.7508 - val_loss: 1.8009 - val_accuracy: 0.4744\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 0.6996 - accuracy: 0.7559 - val_loss: 1.8363 - val_accuracy: 0.4880\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 0.6759 - accuracy: 0.7633 - val_loss: 1.8611 - val_accuracy: 0.4772\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 0.6568 - accuracy: 0.7701 - val_loss: 1.8816 - val_accuracy: 0.4816\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 0.6348 - accuracy: 0.7800 - val_loss: 1.9246 - val_accuracy: 0.4776\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=100, validation_data=(X_val_scaled, y_val),callbacks=[checkpoint_cb,es_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 4ms/step - loss: 3.4557 - accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.455657720565796, 0.10000000149011612]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('models/ch_11/ex_final_model_8d.h5')\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has overfitted the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Try regularizing the model with alpha dropout. Then, without retraining your model, see if you can achieve better accuracy using MC Dropout.\n",
    "\n",
    "f. Retrain your model using 1cycle scheduling and see if it improves training speed and model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layers_drp(model, n_neurons = 100, n_layers_hidden = 20, activation_func = \"elu\", init = \"he_normal\",drp_rate = 0.2):\n",
    "    for layer in range(0,n_layers_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation = activation_func, kernel_initializer = init ))\n",
    "        model.add(keras.layers.AlphaDropout(rate = drp_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32,32,3]))\n",
    "add_layers_drp(model,100,20,\"selu\",\"lecun_normal\",0.1)\n",
    "model.add(keras.layers.Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-5\n",
    "opt = tf.keras.optimizers.Nadam(learning_rate=lr)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"models/ch_11/ex_early_stopping_8e.h5\", save_best_only=True)\n",
    "es_cb = keras.callbacks.EarlyStopping(patience = 20, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer= opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 66s 18ms/step - loss: 2.6676 - accuracy: 0.1338 - val_loss: 2.5165 - val_accuracy: 0.2288\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 2.3544 - accuracy: 0.1695 - val_loss: 2.3342 - val_accuracy: 0.2444\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 2.2043 - accuracy: 0.2020 - val_loss: 2.2429 - val_accuracy: 0.2444\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 2.1084 - accuracy: 0.2176 - val_loss: 2.2771 - val_accuracy: 0.2382\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 26s 18ms/step - loss: 2.0490 - accuracy: 0.2273 - val_loss: 2.2396 - val_accuracy: 0.2514\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 2.0150 - accuracy: 0.2302 - val_loss: 2.2478 - val_accuracy: 0.2634\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 25s 17ms/step - loss: 1.9764 - accuracy: 0.2398 - val_loss: 2.4080 - val_accuracy: 0.2558\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 25s 18ms/step - loss: 1.9542 - accuracy: 0.2457 - val_loss: 2.3326 - val_accuracy: 0.2726\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.9426 - accuracy: 0.2498 - val_loss: 2.4762 - val_accuracy: 0.2570\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.9225 - accuracy: 0.2548 - val_loss: 2.5563 - val_accuracy: 0.2670\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 26s 18ms/step - loss: 1.9049 - accuracy: 0.2613 - val_loss: 2.8847 - val_accuracy: 0.2678\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.8939 - accuracy: 0.2654 - val_loss: 2.9771 - val_accuracy: 0.2640\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 38s 27ms/step - loss: 1.8815 - accuracy: 0.2682 - val_loss: 3.2400 - val_accuracy: 0.2726\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 30s 21ms/step - loss: 1.8727 - accuracy: 0.2723 - val_loss: 3.6268 - val_accuracy: 0.2776\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 1.8548 - accuracy: 0.2786 - val_loss: 3.3650 - val_accuracy: 0.2814\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 25s 18ms/step - loss: 1.8469 - accuracy: 0.2822 - val_loss: 3.7327 - val_accuracy: 0.2950\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.8317 - accuracy: 0.2884 - val_loss: 4.2800 - val_accuracy: 0.2892\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 25s 18ms/step - loss: 1.8216 - accuracy: 0.2954 - val_loss: 4.1431 - val_accuracy: 0.2940\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 30s 21ms/step - loss: 1.8073 - accuracy: 0.3034 - val_loss: 4.4524 - val_accuracy: 0.3040\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.7965 - accuracy: 0.3126 - val_loss: 4.2577 - val_accuracy: 0.3146\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.7812 - accuracy: 0.3183 - val_loss: 4.7140 - val_accuracy: 0.3254\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.7631 - accuracy: 0.3237 - val_loss: 4.3646 - val_accuracy: 0.3308\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.7542 - accuracy: 0.3364 - val_loss: 4.4136 - val_accuracy: 0.3350\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 29s 20ms/step - loss: 1.7426 - accuracy: 0.3411 - val_loss: 4.1371 - val_accuracy: 0.3414\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.7280 - accuracy: 0.3479 - val_loss: 4.8173 - val_accuracy: 0.3414\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=100, validation_data=(X_val_scaled, y_val),callbacks=[checkpoint_cb,es_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 2.2358 - accuracy: 0.2532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2357561588287354, 0.2531999945640564]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('models/ch_11/ex_final_model_8e.h5')\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 4s 3ms/step - loss: 2.2271 - accuracy: 0.2517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.227123260498047, 0.2516666650772095]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas = np.stack([model(X_test_scaled, training=True) for sample in range(100)])\n",
    "y_proba = y_probas.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(y_proba, axis=1) \n",
    "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "print(accuracy) ##increased from 86.2 to 86.5 using mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TO review the cause of overfitting and add - One cycle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hands-on-ml-book",
   "language": "python",
   "name": "hands-on-ml-book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
