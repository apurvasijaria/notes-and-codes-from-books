{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "\n",
    "- powerful and versatile machine learning algorithms\n",
    "- capable of performing linear or non linear classification, regression, and even outlier detection.\n",
    "- well suited for classification of complex small and medium size dataset \n",
    "\n",
    "### Linear SVM Classification\n",
    "\n",
    "We can use linear SVM when we have two classes that clearly can be separated easily with a straight line (they are linearly separable).\n",
    "\n",
    "**Large Margin Classification**\n",
    "- SVM classifies two binary classed with maximum possible distance  \n",
    "- Dependent on the instance on the edge of the street (called support vectors)\n",
    "- SVMs are sensitive to the feature scales\n",
    "- only works if data is linearly separable\n",
    "- sesnsitive to outliers\n",
    "\n",
    "**Soft Margin Classification**\n",
    "- modified version of the hard margin classification, in hard margin classification the data is completely linearly separable, which is not always the case in practical examples due to a few outliers. If we put the separation based on these outliers the final decision boundary maybe very different from desired and the model may not generalize well. Hence we use soft margin classification. \n",
    "- objective is to find a good balance between keeping the street as large as possible and limiting the margin violations\n",
    "- when creating a SVM model, we can specify a number of hyperparamters. C is one of thoe hyperparamters (which defines the balance).  \n",
    "    - high c - too soft, many boundary violations\n",
    "    - small c - too hard, strict boundaries\n",
    "- If our SVM model is overfitting, we can try regularizing it by reducing C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Applying SVM on classification problem\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Understanding data\n",
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Set has 4 features and 3 target classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assigning X and Y\n",
    "## Only taking petal features (length and width) and virginica target class\n",
    "X= iris[\"data\"][:,(2,3)]\n",
    "y= (iris[\"target\"] == 2).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating SVM Pipeline\n",
    "svm_clf = Pipeline([\n",
    "    (\"scaler\",StandardScaler()),\n",
    "    (\"linear_svc\",LinearSVC(C=1,loss=\"hinge\")),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('linear_svc', LinearSVC(C=1, loss='hinge'))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Fitting the pipeline of models and preprocessing to the feature set \n",
    "svm_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/ch_05/hinge_svm_clf.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(svm_clf,'models/ch_05/hinge_svm_clf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Predictive a random feature\n",
    "svm_clf.predict([[5.5,1.7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot x and y and model\n",
    "y_pred = svm_clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b41f32b9d0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(X[:,1],X[:,0],\"b.\")\n",
    "plt.plot(X[:,1],y_pred,\"r.\")\n",
    "plt.plot(y_pred,X[:,0],\"g.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Linear kernal in SVC instead of using Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = Pipeline([\n",
    "    (\"scaler\",StandardScaler()),\n",
    "    (\"scv_linear\",SVC(C=1,kernel=\"linear\")),\n",
    "])\n",
    "\n",
    "svm_clf.fit(X,y)\n",
    "print(svm_clf.predict([[5.5,1.7]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/ch_05/linear_svm_clf.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(svm_clf,'models/ch_05/linear_svm_clf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike linear regression, SVM has no output of probabilites for each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using SGDClassifier \n",
    "\n",
    "- in loss function the possible options are \n",
    "    - ‘hinge’,\n",
    "    - ‘log’, \n",
    "    - ‘modified_huber’, \n",
    "    - ‘squared_hinge’, \n",
    "    - ‘perceptron’,\n",
    "    - or a regression loss: \n",
    "        - ‘squared_loss’, \n",
    "        - ‘huber’, \n",
    "        - ‘epsilon_insensitive’, \n",
    "        - or ‘squared_epsilon_insensitive’.\n",
    "\n",
    "The ‘log’ loss gives logistic regression, a probabilistic classifier. ‘modified_huber’ is another smooth loss that brings tolerance to outliers as well as probability estimates. ‘squared_hinge’ is like hinge but is quadratically penalized. ‘perceptron’ is the linear loss used by the perceptron algorithm. The other losses are designed for regression but can be useful in classification as well; see SGDRegressor for a description.\n",
    "\n",
    "- alpha : \n",
    "    - Constant that multiplies the regularization term. \n",
    "    - The higher the value, the stronger the regularization. \n",
    "    - used in calculation of learning rate\n",
    "- LR: \n",
    "    - ‘constant’: eta = eta0\n",
    "    - ‘optimal’: \n",
    "        - eta = 1.0 / (alpha * (t + t0)) \n",
    "        - where t0 is chosen by a heuristic proposed by Leon Bottou.\n",
    "    - ‘invscaling’: eta = eta0 / pow(t, power_t)\n",
    "    - ‘adaptive’: eta = eta0,  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "C =1 \n",
    "m = 1000\n",
    "\n",
    "sgd_clf = Pipeline([\n",
    "    (\"scaler\",StandardScaler()),\n",
    "    (\"sgd_linear\",SGDClassifier(loss=\"hinge\",alpha =1/(m*C))),\n",
    "])\n",
    "\n",
    "sgd_clf.fit(X,y)\n",
    "print(sgd_clf.predict([[5.5,1.7]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/ch_05/hinge_sgd_clf.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(sgd_clf,'models/ch_05/hinge_sgd_clf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonlinear SVM Classification \n",
    "\n",
    "In practical cases most datasets are not linearly separable. To handle, non linear cases we can add polynomial features. Testing out one such case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_moons(n_samples = 100, noise = 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Understanding the dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.18758623,  0.80416205],\n",
       "       [ 0.04159605,  1.0883423 ],\n",
       "       [-0.88695182,  0.20442036],\n",
       "       [ 1.66692478, -0.42501941],\n",
       "       [ 1.80075716,  0.57651335]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1b42083d7f0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatter = plt.scatter(X[:,0],X[:,1],c=y, label = y)\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X0')\n",
    "plt.legend(handles=scatter.legend_elements()[0],\n",
    "           labels=[0,1],\n",
    "           title=\"Target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y) ##Target levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a polynomial variable and trianing the linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf_poly = Pipeline([\n",
    "    (\"poly_features\",PolynomialFeatures(degree=3)),\n",
    "    (\"scaler\",StandardScaler()),\n",
    "    (\"svm_clf\",LinearSVC(C=10,loss=\"hinge\")),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apurv\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('poly_features', PolynomialFeatures(degree=3)),\n",
       "                ('scaler', StandardScaler()),\n",
       "                ('svm_clf', LinearSVC(C=10, loss='hinge'))])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf_poly.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/ch_05/poly_svm_clf.pkl']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(svm_clf_poly,'models/ch_05/poly_svm_clf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Kernel\n",
    "\n",
    "- adding polynomial variables works well for lower degree of freedom, but it makes the training slow ofr higher degrees. Instead of using the polynormal variables, we can do the __kernel trick__\n",
    "- the kernel trick makes it possible to get the same result if you had added many polynomial features, even with high degree polynomials, without actually having to add them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_kernel_poly = Pipeline([\n",
    "    (\"scaler\",StandardScaler()),\n",
    "    (\"svm_clf\",SVC(kernel=\"poly\",degree=3,coef0=1,C=5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('svm_clf', SVC(C=5, coef0=1, kernel='poly'))])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_kernel_poly.fit(X,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/ch_05/svm_kernel_poly.pkl']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(svm_kernel_poly,'models/ch_05/svm_kernel_poly.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This trains the model exactly same as adding the polynomial feature in the dataset and training. If the model is overfitting, we might reduce the polynomial degree. If the model is underfitting, we can try to increase it. The paramter ```coef0``` controls how the model is influenced by high degree polynomials vs low degree polynomials.\n",
    "\n",
    "We can use gridsearch to find the correct hyperparamters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Features\n",
    "\n",
    "- to tackle the non linear problems \n",
    "- measures how each features resembles a particular landmark by puting values in the similarty function (eg: gaussian rbf) and comparing to landmark \n",
    "- creating landmark\n",
    "    - transforming each and every instance to a landmark and make it more probable to be a linearly separable dataset\n",
    "    - downside: \n",
    "        - increases the number of features\n",
    "        - computationally expensive\n",
    "        \n",
    "#### Gaussian RBF Kernel\n",
    "\n",
    "- usign the rbf kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('svm_clf', SVC(C=0.001, gamma=5))])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_kernel_svm_clf = Pipeline([\n",
    "(\"scaler\", StandardScaler()),\n",
    "(\"svm_clf\", SVC(kernel=\"rbf\", gamma=5, C=0.001))\n",
    "])\n",
    "rbf_kernel_svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/ch_05/rbf_kernel_svm_clf.pkl']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rbf_kernel_svm_clf,'models/ch_05/rbf_kernel_svm_clf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as C or Y increased it starts to overfit \n",
    "\n",
    "-------\n",
    "- Other kernels exist but are used much more rarely. \n",
    "- Some kernels are specialized for specific data structures. \n",
    "    - String kernels are sometimes used when classifying text documents or DNA sequences (e.g., using the string subsequence kernel or kernels based on the Levenshtein distance).\n",
    "    \n",
    "##### How to choose the kernel\n",
    "\n",
    "- start with linear kernel (if large dataset)\n",
    "    - SVC linear is fasters than SVC (kernel =linear)\n",
    "- start with rbf ( medium or small dataset)\n",
    "- experiment with a few other kernels, using cross-validation and grid search.\n",
    "\n",
    "#### Computational Complexity\n",
    "\n",
    "|Class | Time Complexity | Out-of-core support | Scaling required | Kernel trick|\n",
    "|:-: | :-: | :-: | :-:| :-:|\n",
    "|SVCLienar | O(m × n) | No | Yes | No\n",
    "|SVC | between O(m^2 × n) and O(m^3 ×n) | No | Yes | Yes |\n",
    "| SGDClassifier | O(m × n) | Yes | Yes | No |\n",
    "\n",
    "### SVM Regression\n",
    "\n",
    "- SVM algorithm is versatile, it is not only used for linear and nonlinear classification byt also for regression.\n",
    "- for regression we need to reverse the objective: instead of trying to fit the largest possible street between two classes while limiting margin violations, SVM Regression tries to fit as many instances as possible on the street while limiting margin violations\n",
    "- The width of the street is controlled by a hyperparameter epsilon\n",
    "- Adding more training instances within the margin does not affect the model’s predictions;thus, the model is said to be ϵ-insensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVR(epsilon=1.5)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "svm_reg = LinearSVR(epsilon=1.5)\n",
    "svm_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/ch_05/svm_reg.pkl']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(svm_reg,\"models/ch_05/svm_reg.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To tackle nonlinear regression tasks, you can use a kernelized SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=100, degree=2, kernel='poly')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Polynomial regression\n",
    "from sklearn.svm import SVR\n",
    "svm_poly_reg = SVR(kernel=\"poly\", degree=2, C=100, epsilon=0.1)\n",
    "svm_poly_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/ch_05/svm_poly_reg.pkl']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(svm_poly_reg,\"models/ch_05/svm_poly_reg.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVR class is the regression equivalent of the SVC class, and the LinearSVR class is the regression equivalent of the LinearSVC class. The LinearSVR class scales linearly with the size of the training set (just like the LinearSVC class), while the SVR class gets much too slow when the training set grows large (just like the SVC class). \n",
    "\n",
    "SVMs can also be used for outlier detection; see Scikit-Learn’s documentation for more details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "### Model Training\n",
    "\n",
    "#### Decision function and predictions\n",
    "\n",
    "The linear SVM classifier model predicts the class of a new instance x by simply computing the decision function w x + b = w x + ⋯ + w x + b. If the result is positive, the predicted class ŷ is the positive class (1), and otherwise it is the negative class (0); \n",
    "Training a linear SVM classifier means finding the values of w and b that make this margin as wide as possible while avoiding margin violations (hard margin) or limiting them (soft margin).\n",
    "\n",
    "#### Training Objective\n",
    "\n",
    "Consider the slope of the decision function: it is equal to the norm of the weight vector, ∥ w ∥. If we divide this slope by 2, the points where the decision function is equal to ±1 are going to be twice as far away from the decision boundary. In other words, dividing the slope by 2 will multiply the margin by 2. The smaller the weight vector w, the larger the margin.\n",
    "\n",
    "So we want to minimize ∥ w ∥ to get a large margin. If we also want to void any margin violations (hard margin), then we need the decision function to be greater than 1 for all positive training instances and lower than –1 for negative training instances. If we define t=–1 for negative instances (if y = 0) and t = 1 for positive instances (if y = 1), then we can express this constraint as t (w x + b) ≥ 1 for all instances. We can therefore express the hard margin linear SVM classifier objective as the constrained optimization problem. \n",
    "\n",
    "For the soft margin optimization, we introduce a slack variable. \n",
    "\n",
    "\n",
    "#### Quadratic Programming\n",
    "\n",
    "Hard and soft margin problems are both convex quadratic optimization problems with linear contraints. One way to train a hard margin linear SVM classifier is to use an off-the-shelf QP solver and pass it the preceding parameters. \n",
    "\n",
    "\n",
    "to do>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "**1. What is the fundamental idea behind Support Vector Machines?**\n",
    "\n",
    "To define space for each cateogry based on the parameters, confining them to particular ranges/functions to predict and classify the target classed\n",
    "\n",
    "**2. What is a support vector?**\n",
    "\n",
    "Support vectors are the instances on based of which the space is divided  for dataset in order to classify their target class\n",
    "\n",
    "**3. Why is it important to scale the inputs when using SVMs?**\n",
    "\n",
    "if not scaled, the SVM may miss out the smaller features \n",
    "\n",
    "**4. Can an SVM classifier output a confidence score when it classifies an instance? What about a probability?**\n",
    "\n",
    "distance from the boundary can be used as a confidence score (not directly used)\n",
    "probability, using log regression or predict_proba() function\n",
    "\n",
    "**5. Should you use the primal or the dual form of the SVM problem to train a model on a training set with millions of instances and hundreds of features?**\n",
    "\n",
    "- primal /dual only in linear svm, dual only in kernal \n",
    "- primal complexity prop to m, dual prop to m2 or m3 \n",
    "\n",
    "**6. Say you’ve trained an SVM classifier with an RBF kernel, but it seems to underfit the training set. Should you increase or decrease γ (gamma)? What about C?**\n",
    "\n",
    "Y /c increase either/both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. How should you set the QP parameters (H, f, A, and b) to solve the soft margin linear SVM classifier problem using an off-the-shelf QP solver?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/support-vector-machine-803884d967e3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Train a LinearSVC on a linearly separable dataset. Then train an SVC and a\n",
    "SGDClassifier on the same dataset. See if you can get them to produce roughly\n",
    "the same model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data',\n",
       " 'target',\n",
       " 'frame',\n",
       " 'target_names',\n",
       " 'DESCR',\n",
       " 'feature_names',\n",
       " 'filename']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Trying the iris dataset\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "list(iris.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (iris[\"target\"] == 2).astype(np.int) ##1 is Iris virginics, else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/ch_05/ex_lin_svm.pkl']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "lin_svm_ex = Pipeline([\n",
    "    (\"scaler\",StandardScaler()),\n",
    "    (\"linear_svc\",LinearSVC(C=1,loss=\"hinge\")),\n",
    "])\n",
    "\n",
    "lin_svm_ex.fit(X,y)\n",
    "print(lin_svm_ex.predict([[1.2],[1.4],[2.3]]))\n",
    "joblib.dump(lin_svm_ex,'models/ch_05/ex_lin_svm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/ch_05/ex_lin_svc.pkl']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "lin_svc_ex = Pipeline([\n",
    "    (\"scaler\",StandardScaler()),\n",
    "    (\"linear_svc\",SVC(C=1,kernel=\"linear\")),\n",
    "])\n",
    "\n",
    "lin_svc_ex.fit(X,y)\n",
    "print(lin_svc_ex.predict([[1.2],[1.4],[2.3]]))\n",
    "joblib.dump(lin_svc_ex,'models/ch_05/ex_lin_svc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/ch_05/ex_lin_sgd.pkl']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "m = 1000\n",
    "C = 1\n",
    "\n",
    "lin_sgd_ex = Pipeline([\n",
    "    (\"scaler\",StandardScaler()),\n",
    "    (\"linear_svc\",SGDClassifier(loss=\"hinge\",alpha =1/(m*C))),\n",
    "])\n",
    "\n",
    "lin_sgd_ex.fit(X,y)\n",
    "print(lin_sgd_ex.predict([[1.2],[1.4],[2.3]]))\n",
    "joblib.dump(lin_sgd_ex,'models/ch_05/ex_lin_sgd.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Train an SVM classifier on the MNIST dataset. Since SVM classifiers are binary classifiers, you will need to use one-versus-the-rest to classify all 10 digits. You may want to tune the hyperparameters using small validation sets to speed up the process. What accuracy can you reach?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version = 1)\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(mnist.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist.data\n",
    "y = mnist.target\n",
    "X_train, X_test, y_train, y_test = X[:60000],X[60000:],y[:60000],y[60000:]\n",
    "\n",
    "ovr_clf = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('svc_ovr',OneVsRestClassifier(estimator=SVC(gamma='auto')))    \n",
    "])\n",
    "\n",
    "scores = cross_val_score(estimator=ovr_clf, X=X_train[:2000], y=y_train[:2000], cv=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88111888 0.81118881 0.87412587 0.76923077 0.81818182 0.87412587\n",
      " 0.87323944]\n",
      "0.8430302092273924\n"
     ]
    }
   ],
   "source": [
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovr_clf.fit(X_train[:2000],y_train[:2000])\n",
    "y_pred = ovr_clf.predict(X_test[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_correct = sum(y_test[:500] == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Accuracy on 500 test samples\n",
    "n_correct/500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/ch_05/ovr_clf_mnist.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(ovr_clf,'models/ch_05/ovr_clf_mnist.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. Train an SVM regressor on the California housing dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "housing_data = pd.read_csv(\"datasets/housing/housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "housing_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.569704</td>\n",
       "      <td>35.631861</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>537.870553</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>206855.816909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.003532</td>\n",
       "      <td>2.135952</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>421.385070</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>115395.615874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.350000</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.800000</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1447.750000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>2.563400</td>\n",
       "      <td>119600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.490000</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>3.534800</td>\n",
       "      <td>179700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.010000</td>\n",
       "      <td>37.710000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>3148.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>605.000000</td>\n",
       "      <td>4.743250</td>\n",
       "      <td>264725.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.310000</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>39320.000000</td>\n",
       "      <td>6445.000000</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>6082.000000</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>500001.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          longitude      latitude  housing_median_age   total_rooms  \\\n",
       "count  20640.000000  20640.000000        20640.000000  20640.000000   \n",
       "mean    -119.569704     35.631861           28.639486   2635.763081   \n",
       "std        2.003532      2.135952           12.585558   2181.615252   \n",
       "min     -124.350000     32.540000            1.000000      2.000000   \n",
       "25%     -121.800000     33.930000           18.000000   1447.750000   \n",
       "50%     -118.490000     34.260000           29.000000   2127.000000   \n",
       "75%     -118.010000     37.710000           37.000000   3148.000000   \n",
       "max     -114.310000     41.950000           52.000000  39320.000000   \n",
       "\n",
       "       total_bedrooms    population    households  median_income  \\\n",
       "count    20433.000000  20640.000000  20640.000000   20640.000000   \n",
       "mean       537.870553   1425.476744    499.539680       3.870671   \n",
       "std        421.385070   1132.462122    382.329753       1.899822   \n",
       "min          1.000000      3.000000      1.000000       0.499900   \n",
       "25%        296.000000    787.000000    280.000000       2.563400   \n",
       "50%        435.000000   1166.000000    409.000000       3.534800   \n",
       "75%        647.000000   1725.000000    605.000000       4.743250   \n",
       "max       6445.000000  35682.000000   6082.000000      15.000100   \n",
       "\n",
       "       median_house_value  \n",
       "count        20640.000000  \n",
       "mean        206855.816909  \n",
       "std         115395.615874  \n",
       "min          14999.000000  \n",
       "25%         119600.000000  \n",
       "50%         179700.000000  \n",
       "75%         264725.000000  \n",
       "max         500001.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537.8705525375618"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_data.total_bedrooms.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_data.total_bedrooms.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_data.total_bedrooms.fillna(housing_data.total_bedrooms.median(),inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20640 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "housing_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "## Adding another categorical variable to categorize income of households \n",
    "housing_data['income_cat'] = pd.cut(housing_data.median_income,\n",
    "                                    bins = [0,1.5,3.0,4.5,6,np.inf],\n",
    "                                    labels = [1,2,3,4,5])\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state=42)\n",
    "for train_index, test_index in split.split(housing_data,housing_data.income_cat):\n",
    "    strat_train_set = housing_data.loc[train_index]\n",
    "    strat_test_set = housing_data.loc[test_index]\n",
    "    \n",
    "\n",
    "    ## removing income cat\n",
    "strat_test_set.drop(\"income_cat\",axis =1,inplace = True )\n",
    "strat_train_set.drop(\"income_cat\",axis =1,inplace = True )\n",
    "\n",
    "    ## removing ocean proximity\n",
    "strat_test_set.drop(\"ocean_proximity\",axis =1,inplace = True )\n",
    "strat_train_set.drop(\"ocean_proximity\",axis =1,inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('regressor', SVR(C=1000, epsilon=0.01, gamma=0.01))])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_housing_reg = Pipeline([\n",
    "    (\"scaler\",StandardScaler()),\n",
    "    (\"regressor\",SVR(kernel='rbf', C=1000, gamma=0.01, epsilon=.01)),\n",
    "    \n",
    "])\n",
    "\n",
    "svm_housing_reg.fit(strat_train_set.drop(\"median_house_value\",axis=1,inplace = False),strat_train_set[\"median_house_value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_housing_reg.predict(strat_test_set.drop(\"median_house_value\",axis=1,inplace = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of sklearn.metrics:\n",
      "MAE: 56560.61898474966\n",
      "MSE: 6222997011.854963\n",
      "RMSE: 78885.97474744775\n",
      "R-Squared: -0.5225718997494855\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "mae = metrics.mean_absolute_error(y_pred, strat_test_set[\"median_house_value\"])\n",
    "mse = metrics.mean_squared_error(y_pred, strat_test_set[\"median_house_value\"])\n",
    "rmse = np.sqrt(mse) # or mse**(0.5)  \n",
    "r2 = metrics.r2_score(y_pred,strat_test_set[\"median_house_value\"])\n",
    "\n",
    "print(\"Results of sklearn.metrics:\")\n",
    "print(\"MAE:\",mae)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R-Squared:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/ch_05/svr_housing_reg.pkl']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(svm_housing_reg,'models/ch_05/svr_housing_reg.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
